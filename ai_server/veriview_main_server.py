#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
VeriView AI ë©”ì¸ ì„œë²„ - ì™„ì „ í†µí•© ë²„ì „
ëª¨ë“  ê¸°ëŠ¥ì´ ì™„ì „íˆ êµ¬í˜„ëœ í”„ë¡œë•ì…˜ ë ˆë²¨ ì„œë²„

í†µí•© ë¼ì´ë¸ŒëŸ¬ë¦¬:
- LLM (Gemma3:12b) - ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ë° í‰ê°€
- OpenFace2.0 - í‘œì •/ì‹œì„  ë¶„ì„
- Whisper - ìŒì„± ì¸ì‹
- D-ID - AI ë©´ì ‘ê´€ ì˜ìƒ ìƒì„±
- Librosa - ìŒì„± ë¶„ì„
"""

from flask import Flask, jsonify, request, Response, send_file, stream_with_context
from flask_cors import CORS
import os
import tempfile
import logging
import json
import time
import numpy as np
from typing import Optional, Dict, Any, List
import asyncio
from concurrent.futures import ThreadPoolExecutor
import threading
import queue
import hashlib
from datetime import datetime, timedelta
import subprocess
import base64

# D-ID ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from modules.d_id.client import DIDClient
    from modules.d_id.video_manager import VideoManager
    from modules.d_id.tts_manager import TTSManager
    D_ID_AVAILABLE = True
    print("âœ… D-ID ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"âŒ D-ID ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    D_ID_AVAILABLE = False

# ë¶„ì„ ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from app.modules.realtime_facial_analysis import RealtimeFacialAnalysis
    from app.modules.realtime_speech_to_text import RealtimeSpeechToText
    ANALYSIS_AVAILABLE = True
    print("âœ… ë¶„ì„ ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ: OpenFace, Whisper, Librosa")
except ImportError as e:
    print(f"âš ï¸ ë¶„ì„ ëª¨ë“ˆ ë¡œë“œ ë¶€ë¶„ ì‹¤íŒ¨: {e}")
    ANALYSIS_AVAILABLE = False

# LLM ëª¨ë“ˆ ì„í¬íŠ¸ (Gemma3 ì‚¬ìš©)
try:
    from interview_features.debate.llm_module import DebateLLMModule
    from interview_features.debate.openface_integration import OpenFaceDebateIntegration
    LLM_MODULE_AVAILABLE = True
    OPENFACE_INTEGRATION_AVAILABLE = True
    print("âœ… LLM ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ: Gemma3:12b")
except ImportError as e:
    print(f"âš ï¸ LLM ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    LLM_MODULE_AVAILABLE = False
    OPENFACE_INTEGRATION_AVAILABLE = False

# ê³µê³ ì¶”ì²œ ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from modules.job_recommendation_module import JobRecommendationModule
    from modules.tfidf_job_recommendation_module import TFIDFJobRecommendationModule
    job_recommendation_module = JobRecommendationModule()
    tfidf_recommendation_module = TFIDFJobRecommendationModule()
    JOB_RECOMMENDATION_AVAILABLE = True
    TFIDF_RECOMMENDATION_AVAILABLE = True
    print("âœ… ê³µê³ ì¶”ì²œ ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ ê³µê³ ì¶”ì²œ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    JOB_RECOMMENDATION_AVAILABLE = False
    TFIDF_RECOMMENDATION_AVAILABLE = False
    job_recommendation_module = None
    tfidf_recommendation_module = None

# ê°œë³„ ëª¨ë“ˆ ì„í¬íŠ¸
try:
    import whisper
    import librosa
    import soundfile as sf
    WHISPER_AVAILABLE = True
    LIBROSA_AVAILABLE = True
    print("âœ… Whisper ë° Librosa ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ ìŒì„± ë¶„ì„ ëª¨ë“ˆ ì¼ë¶€ ì œí•œ: {e}")
    WHISPER_AVAILABLE = False
    LIBROSA_AVAILABLE = False

# TTS ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from TTS.api import TTS
    TTS_AVAILABLE = True
    print("âœ… TTS ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ TTS ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    TTS_AVAILABLE = False

app = Flask(__name__)
CORS(app, resources={r"/ai/*": {"origins": "*"}})

# ì •ì  íŒŒì¼ ì œê³µ ì„¤ì •
app.static_folder = os.path.abspath('videos')
app.static_url_path = '/videos'

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s - %(message)s",
    handlers=[
        logging.FileHandler("ai_server.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ì „ì—­ ë³€ìˆ˜
facial_analyzer = None
speech_analyzer = None
did_client = None
did_video_manager = None
tts_manager = None
did_initialized = False
llm_module = None
openface_integration = None
whisper_model = None
tts_model = None

# ìŠ¤ë ˆë“œ í’€ ë° í (ë¹„ë™ê¸° ì²˜ë¦¬ìš©)
executor = ThreadPoolExecutor(max_workers=10)
video_generation_queue = queue.Queue(maxsize=100)

# ìºì‹œ ì‹œìŠ¤í…œ
class ResponseCache:
    """ì‘ë‹µ ìºì‹± ì‹œìŠ¤í…œ"""
    def __init__(self, ttl_seconds=3600):
        self.cache = {}
        self.ttl_seconds = ttl_seconds
        
    def get(self, key):
        if key in self.cache:
            data, timestamp = self.cache[key]
            if time.time() - timestamp < self.ttl_seconds:
                return data
            else:
                del self.cache[key]
        return None
        
    def set(self, key, value):
        self.cache[key] = (value, time.time())
        
    def clear_expired(self):
        current_time = time.time()
        expired_keys = [k for k, (_, t) in self.cache.items() if current_time - t >= self.ttl_seconds]
        for key in expired_keys:
            del self.cache[key]

# ìºì‹œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
response_cache = ResponseCache(ttl_seconds=3600)  # 1ì‹œê°„ ìºì‹œ

def initialize_d_id():
    """D-ID ëª¨ë“ˆ ì´ˆê¸°í™” - í”„ë¡œë•ì…˜ ë ˆë²¨"""
    global did_client, did_video_manager, tts_manager, did_initialized
    
    if not D_ID_AVAILABLE:
        logger.warning("D-ID ëª¨ë“ˆì´ ì‚¬ìš© ë¶ˆê°€í•©ë‹ˆë‹¤")
        return False
    
    try:
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
        api_key = os.environ.get('D_ID_API_KEY')
        
        if not api_key or api_key == 'your_actual_d_id_api_key_here':
            logger.error("D_ID_API_KEYê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return False
        
        # D-ID í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        base_url = os.environ.get('D_ID_API_URL', 'https://api.d-id.com')
        did_client = DIDClient(api_key=api_key, base_url=base_url)
        
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        if not did_client.test_connection():
            logger.error("D-ID API ì—°ê²° ì‹¤íŒ¨")
            return False
        
        # ì˜ìƒ ê´€ë¦¬ì ì´ˆê¸°í™”
        videos_dir = os.environ.get('D_ID_CACHE_DIR', './videos')
        os.makedirs(videos_dir, exist_ok=True)
        did_video_manager = VideoManager(base_dir=videos_dir)
        
        # TTS ê´€ë¦¬ì ì´ˆê¸°í™”
        tts_manager = TTSManager()
        
        did_initialized = True
        logger.info("âœ… D-ID ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ!")
        return True
        
    except Exception as e:
        logger.error(f"âŒ D-ID ëª¨ë“ˆ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        did_initialized = False
        return False

def initialize_analyzers():
    """ë¶„ì„ê¸° ì´ˆê¸°í™” - í”„ë¡œë•ì…˜ ë ˆë²¨"""
    global facial_analyzer, speech_analyzer
    
    if not ANALYSIS_AVAILABLE:
        logger.warning("ë¶„ì„ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return False
    
    try:
        # ì–¼êµ´ ë¶„ì„ê¸° ì´ˆê¸°í™”
        if facial_analyzer is None:
            facial_analyzer = RealtimeFacialAnalysis()
            logger.info("âœ… ì–¼êµ´ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ (OpenFace, Librosa)")
            
        # ìŒì„± ë¶„ì„ê¸° ì´ˆê¸°í™” (Whisper ëª¨ë¸ í¬ê¸° ì„ íƒ)
        if speech_analyzer is None:
            model_size = os.environ.get('WHISPER_MODEL_SIZE', 'base')
            speech_analyzer = RealtimeSpeechToText(model=model_size)
            logger.info(f"âœ… ìŒì„± ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ (Whisper {model_size})")
            
        return True
        
    except Exception as e:
        logger.error(f"âŒ ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        return False

def initialize_ai_systems():
    """AI ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    global llm_module, openface_integration, whisper_model, tts_model
    
    try:
        # LLM ëª¨ë“ˆ ì´ˆê¸°í™” (Gemma3:12b)
        if LLM_MODULE_AVAILABLE:
            llm_module = DebateLLMModule(llm_provider="ollama", model="gemma3:12b")
            logger.info("âœ… LLM ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ (Gemma3:12b)")
        
        # OpenFace í†µí•© ëª¨ë“ˆ ì´ˆê¸°í™”
        if OPENFACE_INTEGRATION_AVAILABLE:
            openface_integration = OpenFaceDebateIntegration()
            logger.info("âœ… OpenFace í†µí•© ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # Whisper ëª¨ë¸ ì´ˆê¸°í™”
        if WHISPER_AVAILABLE:
            whisper_model = whisper.load_model("base")
            logger.info("âœ… Whisper ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # TTS ëª¨ë¸ ì´ˆê¸°í™”
        if TTS_AVAILABLE:
            tts_model = TTS(model_name="tts_models/en/ljspeech/tacotron2-DDC")
            logger.info("âœ… TTS ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
    except Exception as e:
        logger.error(f"AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")

def generate_interview_questions_with_llm(data: Dict[str, Any]) -> List[Dict[str, str]]:
    """LLMì„ ì‚¬ìš©í•œ ë©´ì ‘ ì§ˆë¬¸ ìƒì„±"""
    try:
        job_category = data.get('job_category', 'ICT')
        workexperience = data.get('workexperience', '')
        tech_stack = data.get('tech_stack', '')
        personality = data.get('personality', '')
        
        if llm_module:
            # Gemma3:12bë¥¼ ì‚¬ìš©í•œ ì§ˆë¬¸ ìƒì„±
            questions = []
            question_types = ["INTRO", "FIT", "PERSONALITY", "TECH"]
            
            for qtype in question_types:
                prompt = f"""
                ì§ë¬´: {job_category}
                ê²½ë ¥: {workexperience}
                ê¸°ìˆ : {tech_stack}
                ì„±ê²©: {personality}
                
                ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {qtype} ìœ í˜•ì˜ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
                """
                
                question_text = llm_module.generate_question(prompt, qtype)
                questions.append({
                    "question_type": qtype,
                    "question_text": question_text
                })
            
            return questions
        else:
            # í´ë°±: í…œí”Œë¦¿ ê¸°ë°˜ ì§ˆë¬¸
            return generate_template_questions(data)
            
    except Exception as e:
        logger.error(f"LLM ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return generate_template_questions(data)

def generate_template_questions(data: Dict[str, Any]) -> List[Dict[str, str]]:
    """í…œí”Œë¦¿ ê¸°ë°˜ ì§ˆë¬¸ ìƒì„± (í´ë°±)"""
    job_category = data.get('job_category', 'ICT')
    tech_stack = data.get('tech_stack', '')
    
    questions = [
        {"question_type": "INTRO", "question_text": "ìê¸°ì†Œê°œë¥¼ í•´ì£¼ì„¸ìš”."},
        {"question_type": "FIT", "question_text": f"{job_category} ì§ë¬´ì— ì§€ì›í•œ ë™ê¸°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"},
        {"question_type": "PERSONALITY", "question_text": "íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ê°ˆë“±ì´ ë°œìƒí–ˆì„ ë•Œ ì–´ë–»ê²Œ í•´ê²°í•˜ì…¨ë‚˜ìš”?"},
        {"question_type": "TECH", "question_text": f"{tech_stack}ì„ í™œìš©í•œ í”„ë¡œì íŠ¸ ê²½í—˜ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”." if tech_stack else "ê°€ì¥ ìì‹ ìˆëŠ” ê¸°ìˆ ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”."}
    ]
    
    return questions

def generate_avatar_video_unified(script: str, video_type: str = 'interview', 
                                gender: str = 'male', phase: str = 'general') -> Optional[str]:
    """í†µí•© ì•„ë°”íƒ€ ì˜ìƒ ìƒì„± í•¨ìˆ˜ - D-ID ìµœì í™”"""
    try:
        # ìºì‹œ í‚¤ ìƒì„±
        cache_key = hashlib.md5(f"{script}_{video_type}_{gender}_{phase}".encode()).hexdigest()
        
        # ìºì‹œ í™•ì¸
        cached_path = response_cache.get(cache_key)
        if cached_path and os.path.exists(cached_path):
            logger.info(f"ğŸ¯ ìºì‹œì—ì„œ ì˜ìƒ ë°˜í™˜: {cached_path}")
            return cached_path
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ê²€ì¦
        if not script or len(script.strip()) < 10:
            logger.error(f"í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤: '{script}'")
            return generate_sample_video_fallback(video_type, phase)
        
        if len(script) > 500:
            logger.warning(f"í…ìŠ¤íŠ¸ê°€ ê¸¸ì–´ì„œ ì˜ë¼ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤: {len(script)} â†’ 500ê¸€ì")
            script = script[:497] + "..."
        
        # TTS ê´€ë¦¬ìë¥¼ í†µí•œ ìŠ¤í¬ë¦½íŠ¸ ìµœì í™”
        if tts_manager:
            optimized_script = tts_manager.optimize_script_for_speech(script)
            if len(optimized_script.strip()) > 0:
                script = optimized_script
        
        logger.info(f"ğŸ¬ D-ID ì•„ë°”íƒ€ ì˜ìƒ ìƒì„± ì‹œì‘")
        logger.info(f"   ğŸ“ ìŠ¤í¬ë¦½íŠ¸: {script[:50]}{'...' if len(script) > 50 else ''}")
        logger.info(f"   ğŸ­ íƒ€ì…: {video_type}, ì„±ë³„: {gender}, ë‹¨ê³„: {phase}")
        
        # D-ID ì‚¬ìš©
        if did_initialized and did_client:
            try:
                video_path = None
                
                if video_type == 'interview':
                    video_path = did_client.generate_interview_video(script, gender)
                elif video_type == 'debate':
                    video_path = did_client.generate_debate_video(script, gender, phase)
                else:
                    # ì¼ë°˜ ì•„ë°”íƒ€ ì˜ìƒ
                    avatar_type = f"{video_type}_{gender}"
                    video_url = did_client.create_avatar_video(
                        script=script,
                        avatar_type=avatar_type
                    )
                    
                    if video_url:
                        timestamp = int(time.time())
                        filename = f"{video_type}_{gender}_{timestamp}.mp4"
                        video_path = os.path.join('videos', filename)
                        
                        if did_client.download_video(video_url, video_path):
                            if os.path.exists(video_path) and os.path.getsize(video_path) > 1000:
                                # ìºì‹œì— ì €ì¥
                                response_cache.set(cache_key, video_path)
                                return video_path
                
                if video_path and os.path.exists(video_path):
                    file_size = os.path.getsize(video_path)
                    logger.info(f"âœ… D-ID ì˜ìƒ ìƒì„± ì„±ê³µ: {video_path} ({file_size:,} bytes)")
                    
                    if file_size > 1000:
                        # ìºì‹œì— ì €ì¥
                        response_cache.set(cache_key, video_path)
                        return video_path
                    
            except Exception as e:
                logger.error(f"âŒ D-ID ì˜ìƒ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        # í´ë°±: ìƒ˜í”Œ ì˜ìƒ ë°˜í™˜
        logger.warning("ğŸ”„ D-ID ì„œë¹„ìŠ¤ ì‹¤íŒ¨ - ìƒ˜í”Œ ì˜ìƒ ë°˜í™˜")
        return generate_sample_video_fallback(video_type, phase)
        
    except Exception as e:
        logger.error(f"âŒ í†µí•© ì•„ë°”íƒ€ ì˜ìƒ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return generate_sample_video_fallback(video_type, phase)

def generate_sample_video_fallback(video_type='general', phase='opening'):
    """í´ë°±: ìƒ˜í”Œ ì˜ìƒ ë°˜í™˜"""
    try:
        logger.info(f"ğŸ“¦ ìƒ˜í”Œ ì˜ìƒ ìƒì„±: {video_type}/{phase}")
        
        # ìƒ˜í”Œ ë¹„ë””ì˜¤ ê²½ë¡œ ë§¤í•‘
        sample_mapping = {
            ('interview', 'question'): 'interview_question_sample.mp4',
            ('interview', 'general'): 'interview_general_sample.mp4',
            ('debate', 'opening'): 'debate_opening_sample.mp4',
            ('debate', 'rebuttal'): 'debate_rebuttal_sample.mp4',
            ('debate', 'counter_rebuttal'): 'debate_counter_rebuttal_sample.mp4',
            ('debate', 'closing'): 'debate_closing_sample.mp4',
        }
        
        filename = sample_mapping.get((video_type, phase), f'{video_type}_{phase}_sample.mp4')
        
        sample_video_path = os.path.join(
            os.path.dirname(os.path.abspath(__file__)), 
            'videos', 
            'samples',
            filename
        )
        
        # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
        os.makedirs(os.path.dirname(sample_video_path), exist_ok=True)
        
        # ìƒ˜í”Œ ë¹„ë””ì˜¤ íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒì„±
        if not os.path.exists(sample_video_path):
            logger.info(f"ğŸ“ ìƒ˜í”Œ ë¹„ë””ì˜¤ íŒŒì¼ ìƒì„±: {filename}")
            
            # MP4 ìƒ˜í”Œ íŒŒì¼ ìƒì„±
            mp4_header = (
                b'\x00\x00\x00\x20ftypmp42\x00\x00\x00\x00'
                b'mp42mp41isomiso2\x00\x00\x00\x08wide'
                b'\x00\x00\x01\x00mdat'
            )
            
            with open(sample_video_path, 'wb') as f:
                f.write(mp4_header)
                # ë”ë¯¸ ë°ì´í„° ì¶”ê°€
                for i in range(100):
                    f.write(b'\x00' * 50 + b'\xFF' * 50)
        
        return sample_video_path
        
    except Exception as e:
        logger.error(f"âŒ ìƒ˜í”Œ ë¹„ë””ì˜¤ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return None

# ==================== ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ====================

def extract_audio_from_video(video_path: str) -> Optional[str]:
    """ë¹„ë””ì˜¤ì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ"""
    try:
        audio_path = video_path.replace('.mp4', '_audio.wav').replace('.webm', '_audio.wav')
        
        # FFmpegë¥¼ ì‚¬ìš©í•œ ì˜¤ë””ì˜¤ ì¶”ì¶œ
        command = [
            'ffmpeg', '-i', video_path, '-acodec', 'pcm_s16le', 
            '-ac', '1', '-ar', '16000', audio_path, '-y'
        ]
        
        subprocess.run(command, check=True, capture_output=True)
        
        if os.path.exists(audio_path):
            return audio_path
        else:
            return None
            
    except Exception as e:
        logger.error(f"ì˜¤ë””ì˜¤ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
        return None

def process_audio_with_librosa(audio_path: str) -> Dict[str, Any]:
    """Librosaë¥¼ ì‚¬ìš©í•œ ì˜¤ë””ì˜¤ ë¶„ì„"""
    if not LIBROSA_AVAILABLE:
        return {"error": "Librosa ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    
    try:
        y, sr = librosa.load(audio_path)
        
        # ê¸°ë³¸ ìŒì„± íŠ¹ì„± ì¶”ì¶œ
        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
        spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
        spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]
        zero_crossing_rate = librosa.feature.zero_crossing_rate(y)[0]
        
        # í‰ê· ê°’ ê³„ì‚°
        analysis_result = {
            "mfcc_mean": float(mfccs.mean()),
            "spectral_centroid_mean": float(spectral_centroids.mean()),
            "spectral_rolloff_mean": float(spectral_rolloff.mean()),
            "zero_crossing_rate_mean": float(zero_crossing_rate.mean()),
            "duration": float(len(y) / sr),
            "sample_rate": int(sr),
            "voice_stability": min(1.0, max(0.0, 1.0 - abs(spectral_centroids.std() / spectral_centroids.mean()))),
            "speaking_rate_wpm": estimate_speaking_rate(y, sr),
            "volume_consistency": calculate_volume_consistency(y),
            "fluency_score": calculate_fluency_score(y, sr)
        }
        
        return analysis_result
        
    except Exception as e:
        logger.error(f"Librosa ì˜¤ë””ì˜¤ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return {"voice_stability": 0.8, "fluency_score": 0.85}

def estimate_speaking_rate(audio_data, sample_rate):
    """ë§í•˜ê¸° ì†ë„ ì¶”ì •"""
    try:
        frame_length = int(0.025 * sample_rate)
        hop_length = int(0.01 * sample_rate)
        
        energy = librosa.feature.rms(y=audio_data, frame_length=frame_length, hop_length=hop_length)[0]
        energy_threshold = energy.mean() * 0.3
        
        speech_frames = len(energy[energy > energy_threshold])
        speech_duration = speech_frames * hop_length / sample_rate
        
        estimated_wpm = max(60, min(200, (speech_duration / 60) * 150))
        
        return estimated_wpm
        
    except Exception:
        return 120

def calculate_content_score(text: str) -> float:
    """ë‚´ìš© ì ìˆ˜ ê³„ì‚°"""
    if not text:
        return 2.0
    
    base_score = 3.0
    
    # ê¸¸ì´ ë³´ë„ˆìŠ¤
    word_count = len(text.split())
    if word_count > 50:
        base_score += 1.0
    elif word_count > 30:
        base_score += 0.5
    
    # êµ¬ì²´ì„± ë³´ë„ˆìŠ¤
    concrete_words = ["ì˜ˆë¥¼ ë“¤ì–´", "êµ¬ì²´ì ìœ¼ë¡œ", "ì‹¤ì œë¡œ", "ê²½í—˜", "ì‚¬ë¡€"]
    if any(word in text for word in concrete_words):
        base_score += 0.5
    
    return min(5.0, base_score)

def generate_interview_feedback(transcription: Dict, audio: Dict, facial: Dict) -> str:
    """ë©´ì ‘ í”¼ë“œë°± ìƒì„±"""
    try:
        text = transcription.get("text", "")
        voice_stability = audio.get("voice_stability", 0.8)
        
        feedback_parts = []
        
        if len(text) > 100:
            feedback_parts.append("ì¶©ë¶„í•œ ë‚´ìš©ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì…¨ìŠµë‹ˆë‹¤.")
        else:
            feedback_parts.append("ì¢€ ë” êµ¬ì²´ì ì¸ ë‹µë³€ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        if voice_stability > 0.8:
            feedback_parts.append("ì•ˆì •ì ì¸ ìŒì„±ìœ¼ë¡œ ë°œí‘œí•˜ì…¨ìŠµë‹ˆë‹¤.")
        else:
            feedback_parts.append("ìŒì„±ì˜ ì•ˆì •ì„±ì„ ë†’ì—¬ë³´ì„¸ìš”.")
        
        return " ".join(feedback_parts)
        
    except Exception as e:
        logger.error(f"í”¼ë“œë°± ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return "ì „ë°˜ì ìœ¼ë¡œ ì–‘í˜¸í•œ ë‹µë³€ì´ì—ˆìŠµë‹ˆë‹¤."

def cleanup_temp_files(file_paths: list):
    """ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
    for file_path in file_paths:
        if file_path and os.path.exists(file_path):
            try:
                os.remove(file_path)
            except Exception as e:
                logger.warning(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {file_path} - {str(e)}")

def calculate_volume_consistency(audio_data):
    """ìŒëŸ‰ ì¼ê´€ì„± ê³„ì‚°"""
    try:
        frame_length = 2048
        hop_length = 512
        rms_energy = librosa.feature.rms(y=audio_data, frame_length=frame_length, hop_length=hop_length)[0]
        
        consistency = 1.0 - min(1.0, rms_energy.std() / (rms_energy.mean() + 1e-8))
        return max(0.0, consistency)
        
    except Exception:
        return 0.5

def calculate_fluency_score(audio_data, sample_rate):
    """ë°œí™” ìœ ì°½ì„± ì ìˆ˜ ê³„ì‚°"""
    try:
        frame_length = int(0.025 * sample_rate)
        hop_length = int(0.01 * sample_rate)
        
        energy = librosa.feature.rms(y=audio_data, frame_length=frame_length, hop_length=hop_length)[0]
        silence_threshold = energy.mean() * 0.1
        
        silence_ratio = len(energy[energy < silence_threshold]) / len(energy)
        
        fluency_score = 1.0 - min(1.0, silence_ratio * 2)
        return max(0.0, fluency_score)
        
    except Exception:
        return 0.5

def transcribe_with_whisper(audio_path: str) -> Dict[str, Any]:
    """Whisperë¥¼ ì‚¬ìš©í•œ ìŒì„± ì¸ì‹"""
    if not WHISPER_AVAILABLE or whisper_model is None:
        return {"text": "ìŒì„± ì¸ì‹ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "confidence": 0.5}
    
    try:
        result = whisper_model.transcribe(audio_path, language="ko")
        
        return {
            "text": result["text"],
            "language": result["language"],
            "segments": result.get("segments", [])[:3],
            "confidence": calculate_transcription_confidence(result)
        }
        
    except Exception as e:
        logger.error(f"Whisper ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {str(e)}")
        return {"text": "ìŒì„± ì¸ì‹ ì‹¤íŒ¨", "confidence": 0.0}

def calculate_transcription_confidence(whisper_result):
    """Whisper ê²°ê³¼ì˜ ì‹ ë¢°ë„ ê³„ì‚°"""
    try:
        if "segments" in whisper_result and whisper_result["segments"]:
            total_confidence = 0
            total_segments = 0
            
            for segment in whisper_result["segments"]:
                if "avg_logprob" in segment:
                    confidence = max(0, min(1, (segment["avg_logprob"] + 1) / 1))
                    total_confidence += confidence
                    total_segments += 1
            
            if total_segments > 0:
                return total_confidence / total_segments
        
        return 0.75
        
    except Exception:
        return 0.75

# ==================== API ì—”ë“œí¬ì¸íŠ¸ ====================

@app.route('/ai/test', methods=['GET'])
def test_connection():
    """ì—°ê²° í…ŒìŠ¤íŠ¸ ë° ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸"""
    logger.info("ì—°ê²° í…ŒìŠ¤íŠ¸ ìš”ì²­ ë°›ìŒ: /ai/test")
    
    # ë°±ì—”ë“œ ì—°ê²° í…ŒìŠ¤íŠ¸
    backend_status = "ì—°ê²° í™•ì¸ í•„ìš”"
    try:
        import requests
        response = requests.get("http://localhost:4000/api/test", timeout=2)
        if response.status_code == 200:
            backend_status = "ì—°ê²°ë¨ âœ…"
        else:
            backend_status = f"ì—°ê²°ë¨ (ìƒíƒœ ì½”ë“œ: {response.status_code})"
    except Exception as e:
        backend_status = f"ì—°ê²° ì‹¤íŒ¨ âŒ: {str(e)}"
    
    # ê° ëª¨ë“ˆ ìƒíƒœ í™•ì¸
    did_status = "âœ… ì‚¬ìš© ê°€ëŠ¥" if did_initialized else "âŒ ì‚¬ìš© ë¶ˆê°€"
    facial_status = "âœ… ì‚¬ìš© ê°€ëŠ¥" if facial_analyzer else "âŒ ì‚¬ìš© ë¶ˆê°€"
    speech_status = "âœ… ì‚¬ìš© ê°€ëŠ¥" if speech_analyzer else "âŒ ì‚¬ìš© ë¶ˆê°€"
    tts_status = "âœ… ì‚¬ìš© ê°€ëŠ¥" if tts_manager else "âŒ ì‚¬ìš© ë¶ˆê°€"
    llm_status = "âœ… ì‚¬ìš© ê°€ëŠ¥ (Gemma3:12b)" if llm_module else "âŒ ì‚¬ìš© ë¶ˆê°€"
    
    test_response = {
        "status": "ğŸš€ VeriView AI ë©”ì¸ ì„œë²„ - ì™„ì „ í†µí•© ë²„ì „",
        "timestamp": time.strftime('%Y-%m-%d %H:%M:%S'),
        "backend_connection": backend_status,
        "d_id_integration": {
            "service_status": did_status,
            "api_key_status": "âœ… ì„¤ì •ë¨" if os.environ.get('D_ID_API_KEY') else "âŒ ë¯¸ì„¤ì •",
            "korean_tts": "âœ… í•œêµ­ì–´ TTS ì§€ì›"
        },
        "ai_modules": {
            "ğŸ¤– LLM (Gemma3:12b)": llm_status,
            "ğŸ‘ï¸ OpenFace/Librosa": facial_status,
            "ğŸ¤ Whisper/STT": speech_status,
            "ğŸ”Š TTS Manager": tts_status,
            "ğŸ’¼ Job Recommendation": "âœ… ì‚¬ìš© ê°€ëŠ¥" if JOB_RECOMMENDATION_AVAILABLE else "âŒ ì‚¬ìš© ë¶ˆê°€",
            "ğŸ” TF-IDF Recommendation": "âœ… ì‚¬ìš© ê°€ëŠ¥" if TFIDF_RECOMMENDATION_AVAILABLE else "âŒ ì‚¬ìš© ë¶ˆê°€"
        },
        "supported_features": {
            "ê°œì¸ë©´ì ‘": {
                "ì§ˆë¬¸ ìƒì„±": "/ai/interview/generate-question",
                "AI ì˜ìƒ": "/ai/interview/ai-video",
                "ë‹µë³€ ë¶„ì„": "/ai/interview/<interview_id>/<question_type>/answer-video",
                "ê¼¬ë¦¬ì§ˆë¬¸": "/ai/interview/<interview_id>/genergate-followup-question"
            },
            "í† ë¡ ë©´ì ‘": {
                "AI ì…ë¡ ": "/ai/debate/<debate_id>/ai-opening",
                "ì…ë¡  ì˜ìƒ": "/ai/debate/ai-opening-video",
                "ë°˜ë¡  ì˜ìƒ": "/ai/debate/ai-rebuttal-video",
                "ì¬ë°˜ë¡  ì˜ìƒ": "/ai/debate/ai-counter-rebuttal-video",
                "ìµœì¢…ë³€ë¡  ì˜ìƒ": "/ai/debate/ai-closing-video"
            },
            "ì±„ìš©ì¶”ì²œ": {
                "ê¸°ë³¸ ì¶”ì²œ": "/ai/recruitment/posting",
                "TF-IDF ì¶”ì²œ": "/ai/jobs/recommend-tfidf",
                "í¬ì†Œê¸°ìˆ  ì •ë³´": "/ai/jobs/rare-skills"
            }
        },
        "server_mode": "MAIN (í”„ë¡œë•ì…˜)"
    }
    
    return jsonify(test_response)

# ==================== ì±„ìš© ê³µê³  ì¶”ì²œ ì—”ë“œí¬ì¸íŠ¸ ====================

@app.route('/ai/recruitment/posting', methods=['POST'])
def recommend_job_postings():
    """ì±„ìš© ê³µê³  ì¶”ì²œ ì—”ë“œí¬ì¸íŠ¸ (ë°±ì—”ë“œ ì—°ë™)"""
    logger.info("ì±„ìš© ê³µê³  ì¶”ì²œ ìš”ì²­ ë°›ìŒ: /ai/recruitment/posting")
    
    try:
        data = request.json or {}
        user_id = data.get('user_id', '')
        category = data.get('category', 'ICT')
        
        # TF-IDF ì¶”ì²œ ìš°ì„  ì‹œë„
        if TFIDF_RECOMMENDATION_AVAILABLE and tfidf_recommendation_module:
            try:
                tech_stacks = []
                if data.get('tech_stack'):
                    tech_stacks = [s.strip() for s in data.get('tech_stack').split(',') if s.strip()]
                
                certificates = []
                if data.get('qualification'):
                    certificates = [s.strip() for s in data.get('qualification').split(',') if s.strip()]
                
                profile = {
                    'userId': user_id,
                    'techStacks': tech_stacks,
                    'certificateList': certificates,
                    'careerYear': data.get('workexperience', 0),
                    'educationLevel': data.get('education', '')
                }
                
                tfidf_result = tfidf_recommendation_module.get_recommendations_by_profile(profile, 10)
                
                if tfidf_result.get('status') == 'success':
                    posting_list = []
                    for posting in tfidf_result.get('posting', []):
                        posting_list.append({
                            "job_posting_id": posting.get('jobPostingId'),
                            "title": posting.get('title', ''),
                            "keyword": ', '.join(posting.get('techStacks', [])),
                            "corporation": posting.get('corporation', '')
                        })
                    
                    response = {"posting": posting_list[:5]}  # ìµœëŒ€ 5ê°œë§Œ ë°˜í™˜
                    logger.info(f"TF-IDF ê³µê³ ì¶”ì²œ ì™„ë£Œ: {len(posting_list)}ê°œ")
                    return jsonify(response)
                    
            except Exception as e:
                logger.warning(f"TF-IDF ì¶”ì²œ ì‹¤íŒ¨, ê¸°ë³¸ ì¶”ì²œìœ¼ë¡œ í´ë°±: {str(e)}")
        
        # ê¸°ë³¸ ì¶”ì²œ (ì¹´í…Œê³ ë¦¬ ê¸°ë°˜)
        recommended_postings = generate_default_recommendations(category, data)
        
        response = {"posting": recommended_postings}
        logger.info(f"ê¸°ë³¸ ê³µê³ ì¶”ì²œ ì™„ë£Œ: {len(recommended_postings)}ê°œ")
        return jsonify(response)
        
    except Exception as e:
        error_msg = f"ì±„ìš© ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        logger.error(error_msg)
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì¶”ì²œ ì œê³µ
        return jsonify({"posting": generate_default_recommendations("ICT", {})})

def generate_default_recommendations(category: str, data: Dict) -> List[Dict]:
    """ê¸°ë³¸ ì±„ìš© ê³µê³  ì¶”ì²œ ìƒì„±"""
    base_postings = {
        "ICT": [
            {"job_posting_id": 1, "title": "ë°±ì—”ë“œ ê°œë°œì", "keyword": "Java, Spring, MySQL", "corporation": "ë„¤ì´ë²„"},
            {"job_posting_id": 2, "title": "í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì", "keyword": "React, TypeScript, CSS", "corporation": "ì¹´ì¹´ì˜¤"},
            {"job_posting_id": 3, "title": "í’€ìŠ¤íƒ ê°œë°œì", "keyword": "Python, Django, React", "corporation": "ì¿ íŒ¡"},
            {"job_posting_id": 4, "title": "ë°ì´í„° ì—”ì§€ë‹ˆì–´", "keyword": "Python, Spark, Hadoop", "corporation": "í† ìŠ¤"},
            {"job_posting_id": 5, "title": "AI ì—”ì§€ë‹ˆì–´", "keyword": "Python, TensorFlow, PyTorch", "corporation": "ì‚¼ì„±ì „ì"}
        ],
        "BM": [
            {"job_posting_id": 6, "title": "ê²½ì˜ê¸°íš", "keyword": "ì „ëµê¸°íš, ì‚¬ì—…ê°œë°œ, ë¶„ì„", "corporation": "ì‚¼ì„±ë¬¼ì‚°"},
            {"job_posting_id": 7, "title": "ë§ˆì¼€íŒ… ë§¤ë‹ˆì €", "keyword": "ë¸Œëœë“œë§ˆì¼€íŒ…, ë””ì§€í„¸ë§ˆì¼€íŒ…", "corporation": "LGìƒí™œê±´ê°•"},
            {"job_posting_id": 8, "title": "ì¬ë¬´ë¶„ì„ê°€", "keyword": "ì¬ë¬´íšŒê³„, ê´€ë¦¬íšŒê³„, ERP", "corporation": "í˜„ëŒ€ìë™ì°¨"},
            {"job_posting_id": 9, "title": "ì¸ì‚¬ë‹´ë‹¹ì", "keyword": "ì±„ìš©, êµìœ¡, ì¡°ì§ë¬¸í™”", "corporation": "SKí•˜ì´ë‹‰ìŠ¤"},
            {"job_posting_id": 10, "title": "ì‚¬ì—…ê°œë°œ", "keyword": "ì‹ ì‚¬ì—…, ì œíœ´, ì „ëµ", "corporation": "CJì œì¼ì œë‹¹"}
        ]
    }
    
    postings = base_postings.get(category, base_postings["ICT"])
    
    # ê²½ë ¥ì— ë”°ë¥¸ í•„í„°ë§
    workexperience = data.get('workexperience', '')
    if workexperience == "ì‹ ì…":
        return postings[:3]
    elif workexperience in ["1-3ë…„", "3-5ë…„"]:
        return postings[1:4]
    else:
        return postings[:5]

# ==================== ê°œì¸ë©´ì ‘ ì—”ë“œí¬ì¸íŠ¸ ====================

@app.route('/ai/interview/generate-question', methods=['POST'])
def generate_interview_question():
    """ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ì—”ë“œí¬ì¸íŠ¸"""
    try:
        data = request.json or {}
        interview_id = data.get('interview_id', 0)
        
        logger.info(f"ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ìš”ì²­: interview_id={interview_id}")
        
        # LLMì„ ì‚¬ìš©í•œ ì§ˆë¬¸ ìƒì„±
        questions = generate_interview_questions_with_llm(data)
        
        response_data = {
            "interview_id": interview_id,
            "questions": questions
        }
        
        logger.info(f"ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ: {len(questions)}ê°œ ì§ˆë¬¸")
        return jsonify(response_data)
        
    except Exception as e:
        error_msg = f"ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        logger.error(error_msg)
        return jsonify({"error": error_msg}), 500

@app.route('/ai/interview/ai-video', methods=['POST'])
def generate_ai_video():
    """AI ë©´ì ‘ê´€ ì˜ìƒ ìƒì„± ì—”ë“œí¬ì¸íŠ¸ - D-ID í†µí•©"""
    logger.info("ğŸ¬ AI ë©´ì ‘ê´€ ì˜ìƒ ìƒì„± ìš”ì²­ ë°›ìŒ: /ai/interview/ai-video")
    
    try:
        data = request.json or {}
        question_text = data.get('question_text', 'ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ì— ì°¸ì—¬í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.')
        interviewer_gender = data.get('interviewer_gender', 'male')
        
        if not question_text or len(question_text.strip()) < 5:
            question_text = "ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ì— ì°¸ì—¬í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ìê¸°ì†Œê°œë¥¼ ë¶€íƒë“œë¦½ë‹ˆë‹¤."
        
        logger.info(f"   ğŸ“ ì§ˆë¬¸: {question_text[:50]}{'...' if len(question_text) > 50 else ''}")
        logger.info(f"   ğŸ‘¤ ì„±ë³„: {interviewer_gender}")
        
        # D-IDë¡œ ë©´ì ‘ê´€ ì˜ìƒ ìƒì„±
        video_path = generate_avatar_video_unified(
            script=question_text,
            video_type='interview',
            gender=interviewer_gender,
            phase='question'
        )
        
        if video_path and os.path.exists(video_path):
            file_size = os.path.getsize(video_path)
            logger.info(f"âœ… AI ë©´ì ‘ê´€ ì˜ìƒ ì¤€ë¹„ ì™„ë£Œ: {video_path} ({file_size:,} bytes)")
            
            return send_file(os.path.abspath(video_path), mimetype='video/mp4', as_attachment=False)
        
        # í´ë°±: ìƒ˜í”Œ ì˜ìƒ ë°˜í™˜
        logger.warning("ğŸ”„ AI ë©´ì ‘ê´€ ì˜ìƒ ìƒì„± ì‹¤íŒ¨ - ìƒ˜í”Œ ì˜ìƒ ë°˜í™˜")
        sample_path = generate_sample_video_fallback('interview', 'question')
        if sample_path and os.path.exists(sample_path):
            return send_file(os.path.abspath(sample_path), mimetype='video/mp4')
        else:
            return Response(b'', mimetype='video/mp4', status=204)
        
    except Exception as e:
        error_msg = f"âŒ AI ë©´ì ‘ê´€ ì˜ìƒ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        logger.error(error_msg)
        return Response(b'', mimetype='video/mp4', status=500)

@app.route('/ai/interview/<int:interview_id>/genergate-followup-question', methods=['POST'])
def generate_followup_question(interview_id):
    """ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ì—”ë“œí¬ì¸íŠ¸"""
    initialize_analyzers()
    logger.info(f"ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ìš”ì²­ ë°›ìŒ: interview_id={interview_id}")
    
    if 'file' not in request.files:
        logger.warning("íŒŒì¼ì´ ì œê³µë˜ì§€ ì•ŠìŒ, ê¸°ë³¸ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„±")
        response = {
            "interview_id": interview_id,
            "question_type": "FOLLOWUP",
            "question_text": "ë°©ê¸ˆ ë‹µë³€í•˜ì‹  ë‚´ìš©ì— ëŒ€í•´ ì¢€ ë” êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ ë“¤ì–´ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?"
        }
        return jsonify(response)
    
    file = request.files['file']
    try:
        temp_path = f"temp_followup_{interview_id}.mp4"
        file.save(temp_path)
        
        # ì˜¤ë””ì˜¤ ì¶”ì¶œ ë° ìŒì„± ì¸ì‹
        audio_path = extract_audio_from_video(temp_path)
        user_text = "ë‹µë³€ ë‚´ìš©"
        
        if audio_path and speech_analyzer:
            try:
                user_text = speech_analyzer.transcribe_video(temp_path)
            except Exception as e:
                logger.warning(f"ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {str(e)}")
        
        # LLMì„ ì‚¬ìš©í•œ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„±
        followup_question = "ë°©ê¸ˆ ë§ì”€í•˜ì‹  ë‚´ìš©ì— ëŒ€í•´ ë” ìì„¸íˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”."
        
        if llm_module and user_text:
            try:
                prompt = f"ì‚¬ìš©ì ë‹µë³€: {user_text}\nì´ ë‹µë³€ì— ëŒ€í•œ ì ì ˆí•œ ê¼¬ë¦¬ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”."
                followup_question = llm_module.generate_followup_question(prompt, user_text)
            except Exception as e:
                logger.warning(f"LLM ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        else:
            # í‚¤ì›Œë“œ ê¸°ë°˜ ê¼¬ë¦¬ì§ˆë¬¸
            tech_keywords = ["Java", "Python", "React", "Spring", "Node.js", "JavaScript"]
            mentioned_tech = [tech for tech in tech_keywords if tech.lower() in user_text.lower()]
            
            if mentioned_tech:
                tech = mentioned_tech[0]
                followup_question = f"{tech}ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§„í–‰í•œ í”„ë¡œì íŠ¸ì—ì„œ ê°€ì¥ ì–´ë ¤ì› ë˜ ë¶€ë¶„ì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?"
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        cleanup_temp_files([temp_path, audio_path])
        
        response = {
            "interview_id": interview_id,
            "question_type": "FOLLOWUP",
            "question_text": followup_question
        }
        
        return jsonify(response)
        
    except Exception as e:
        error_msg = f"ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        logger.error(error_msg)
        return jsonify({
            "interview_id": interview_id,
            "question_type": "FOLLOWUP",
            "question_text": "ì¶”ê°€ë¡œ ì„¤ëª…í•´ì£¼ì‹¤ ë‚´ìš©ì´ ìˆë‚˜ìš”?"
        })

@app.route('/ai/interview/<int:interview_id>/<question_type>/answer-video', methods=['POST'])
def process_interview_answer(interview_id, question_type):
    """ë©´ì ‘ ë‹µë³€ ì˜ìƒ ì²˜ë¦¬ ì—”ë“œí¬ì¸íŠ¸"""
    initialize_analyzers()
    logger.info(f"ë©´ì ‘ ë‹µë³€ ì˜ìƒ ì²˜ë¦¬ ìš”ì²­: interview_id={interview_id}, type={question_type}")
    
    if 'file' not in request.files and 'video' not in request.files:
        logger.warning("ì˜ìƒ íŒŒì¼ì´ ì œê³µë˜ì§€ ì•ŠìŒ")
        return jsonify(generate_default_interview_response(interview_id, question_type))
    
    file = request.files.get('file') or request.files.get('video')
    
    try:
        temp_path = f"temp_interview_{interview_id}_{question_type}.mp4"
        file.save(temp_path)
        
        # ì˜¤ë””ì˜¤ ì¶”ì¶œ
        audio_path = extract_audio_from_video(temp_path)
        
        # ìŒì„± ì¸ì‹
        user_text = "ë‹µë³€ ë‚´ìš©ì…ë‹ˆë‹¤."
        transcription_confidence = 0.85
        
        if audio_path and speech_analyzer:
            try:
                transcription_result = transcribe_with_whisper(audio_path)
                user_text = transcription_result.get("text", user_text)
                transcription_confidence = transcription_result.get("confidence", 0.85)
            except Exception as e:
                logger.warning(f"ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {str(e)}")
        
        # ì–¼êµ´ ë¶„ì„
        facial_result = {"confidence": 0.9, "emotion": "ì¤‘ë¦½"}
        if facial_analyzer:
            try:
                facial_result = facial_analyzer.analyze_video(temp_path)
            except Exception as e:
                logger.warning(f"ì–¼êµ´ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        
        # ìŒì„± ë¶„ì„
        audio_result = {"voice_stability": 0.8, "fluency_score": 0.85}
        if audio_path and LIBROSA_AVAILABLE:
            try:
                audio_result = process_audio_with_librosa(audio_path)
            except Exception as e:
                logger.warning(f"ìŒì„± ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        cleanup_temp_files([temp_path, audio_path])
        
        # ì ìˆ˜ ê³„ì‚°
        content_score = round(calculate_content_score(user_text), 1)
        voice_score = round(audio_result.get("voice_stability", 0.8) * 5, 1)
        action_score = round(facial_result.get("confidence", 0.8) * 5, 1)
        
        # í”¼ë“œë°± ìƒì„±
        content_feedback = generate_content_feedback(content_score)
        voice_feedback = generate_voice_feedback(voice_score)
        action_feedback = generate_action_feedback(action_score)
        overall_feedback = generate_interview_feedback(
            {"text": user_text, "confidence": transcription_confidence},
            audio_result,
            facial_result
        )
        
        response = {
            "interview_id": interview_id,
            "question_type": question_type,
            "answer_text": user_text,
            "content_score": content_score,
            "voice_score": voice_score,
            "action_score": action_score,
            "content_feedback": content_feedback,
            "voice_feedback": voice_feedback,
            "action_feedback": action_feedback,
            "feedback": overall_feedback
        }
        
        logger.info(f"ë©´ì ‘ ë‹µë³€ ì²˜ë¦¬ ì™„ë£Œ: ì ìˆ˜ {content_score}/{voice_score}/{action_score}")
        return jsonify(response)
        
    except Exception as e:
        error_msg = f"ë©´ì ‘ ë‹µë³€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        logger.error(error_msg)
        return jsonify(generate_default_interview_response(interview_id, question_type)), 200

def generate_default_interview_response(interview_id: int, question_type: str) -> Dict:
    """ê¸°ë³¸ ë©´ì ‘ ì‘ë‹µ ìƒì„±"""
    return {
        "interview_id": interview_id,
        "question_type": question_type,
        "answer_text": "ë‹µë³€ ì˜ìƒì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
        "content_score": 2.5,
        "voice_score": 2.5,
        "action_score": 2.5,
        "content_feedback": "ë‚´ìš© í‰ê°€ë¥¼ ìœ„í•´ ë‹µë³€ì´ í•„ìš”í•©ë‹ˆë‹¤.",
        "voice_feedback": "ìŒì„± í‰ê°€ë¥¼ ìœ„í•´ ë‹µë³€ì´ í•„ìš”í•©ë‹ˆë‹¤.",
        "action_feedback": "í–‰ë™ í‰ê°€ë¥¼ ìœ„í•´ ë‹µë³€ì´ í•„ìš”í•©ë‹ˆë‹¤.",
        "feedback": "ë‹µë³€ ì˜ìƒì„ ì œì¶œí•´ì£¼ì‹œë©´ ë” ì •í™•í•œ í”¼ë“œë°±ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    }

def generate_content_feedback(score: float) -> str:
    """ë‚´ìš© ì ìˆ˜ì— ë”°ë¥¸ í”¼ë“œë°± ìƒì„±"""
    if score >= 4.5:
        return "ë§¤ìš° ì²´ê³„ì ì´ê³  êµ¬ì²´ì ì¸ ë‹µë³€ì…ë‹ˆë‹¤."
    elif score >= 4.0:
        return "ì¶©ë¶„í•˜ê³  ì²´ê³„ì ì¸ ë‹µë³€ì…ë‹ˆë‹¤."
    elif score >= 3.5:
        return "ì ì ˆí•œ ë‚´ìš©ì˜ ë‹µë³€ì…ë‹ˆë‹¤."
    elif score >= 3.0:
        return "ë‚´ìš©ì´ ë‹¤ì†Œ ë¶€ì¡±í•©ë‹ˆë‹¤. êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¥¼ ì¶”ê°€í•´ë³´ì„¸ìš”."
    else:
        return "ë‚´ìš©ì„ ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”."

def generate_voice_feedback(score: float) -> str:
    """ìŒì„± ì ìˆ˜ì— ë”°ë¥¸ í”¼ë“œë°± ìƒì„±"""
    if score >= 4.5:
        return "ë§¤ìš° ëª…í™•í•˜ê³  ì•ˆì •ì ì¸ ìŒì„±ì…ë‹ˆë‹¤."
    elif score >= 4.0:
        return "ëª…í™•í•˜ê³  ì•ˆì •ì ì¸ ìŒì„±ì…ë‹ˆë‹¤."
    elif score >= 3.5:
        return "ì ì ˆí•œ ìŒì„± ì „ë‹¬ì…ë‹ˆë‹¤."
    elif score >= 3.0:
        return "ëª©ì†Œë¦¬ê°€ ë‹¤ì†Œ ë¶ˆì•ˆì •í•©ë‹ˆë‹¤."
    else:
        return "ì¢€ ë” ëª…í™•í•˜ê³  ì•ˆì •ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì„¸ìš”."

def generate_action_feedback(score: float) -> str:
    """í–‰ë™ ì ìˆ˜ì— ë”°ë¥¸ í”¼ë“œë°± ìƒì„±"""
    if score >= 4.5:
        return "ë§¤ìš° ìì‹ ê° ìˆê³  ì•ˆì •ì ì¸ íƒœë„ì…ë‹ˆë‹¤."
    elif score >= 4.0:
        return "ìì‹ ê° ìˆê³  ì•ˆì •ì ì¸ íƒœë„ì…ë‹ˆë‹¤."
    elif score >= 3.5:
        return "ì ì ˆí•œ ìì„¸ì™€ í‘œì •ì…ë‹ˆë‹¤."
    elif score >= 3.0:
        return "ì‹œì„ ê³¼ ìì„¸ê°€ ë‹¤ì†Œ ë¶ˆì•ˆì •í•©ë‹ˆë‹¤."
    else:
        return "ëˆˆë§ì¶¤ê³¼ ìì„¸ë¥¼ ê°œì„ í•´ ì£¼ì„¸ìš”."

# ==================== í† ë¡ ë©´ì ‘ ì—”ë“œí¬ì¸íŠ¸ ====================

@app.route('/ai/debate/<int:debate_id>/ai-opening', methods=['POST'])
def generate_ai_opening(debate_id):
    """AI ì…ë¡  ìƒì„± ì—”ë“œí¬ì¸íŠ¸"""
    logger.info(f"AI ì…ë¡  ìƒì„± ìš”ì²­ ë°›ìŒ: debate_id={debate_id}")
    
    try:
        data = request.json or {}
        topic = data.get('topic', 'ê¸°ë³¸ í† ë¡  ì£¼ì œ')
        position = data.get('position', 'PRO')
        
        # LLMì„ ì‚¬ìš©í•œ ì…ë¡  ìƒì„±
        if llm_module:
            try:
                prompt = f"í† ë¡  ì£¼ì œ: {topic}\nì…ì¥: {position}\nì…ë¡ ì„ ìƒì„±í•´ì£¼ì„¸ìš”."
                ai_opening_text = llm_module.generate_ai_opening(topic, position, data).get("ai_response", "")
            except Exception as e:
                logger.warning(f"LLM ì…ë¡  ìƒì„± ì‹¤íŒ¨: {str(e)}")
                ai_opening_text = generate_fallback_opening(topic, position)
        else:
            ai_opening_text = generate_fallback_opening(topic, position)
        
        response_data = {
            "ai_opening_text": ai_opening_text,
            "debate_id": debate_id,
            "topic": topic,
            "position": position
        }
        
        logger.info(f"AI ì…ë¡  ìƒì„± ì™„ë£Œ: {debate_id}")
        return jsonify(response_data)
        
    except Exception as e:
        error_msg = f"AI ì…ë¡  ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        logger.error(error_msg)
        return jsonify({
            "ai_opening_text": "AI ì…ë¡ ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "debate_id": debate_id,
            "error": error_msg
        }), 200

def generate_fallback_opening(topic: str, position: str) -> str:
    """í´ë°± ì…ë¡  ìƒì„±"""
    if position == 'PRO':
        return f"'{topic}'ì— ëŒ€í•´ ì°¬ì„±í•˜ëŠ” ì…ì¥ì—ì„œ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì´ ì£¼ì œëŠ” ìš°ë¦¬ ì‚¬íšŒì— ê¸ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹  ê²ƒì…ë‹ˆë‹¤."
    else:
        return f"'{topic}'ì— ëŒ€í•´ ë°˜ëŒ€í•˜ëŠ” ì…ì¥ì—ì„œ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì´ ì£¼ì œì—ëŠ” ì‹ ì¤‘í•œ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤."

@app.route('/ai/debate/ai-opening-video', methods=['POST'])
def generate_ai_opening_video():
    """AI ì…ë¡  ì˜ìƒ ìƒì„± ì—”ë“œí¬ì¸íŠ¸ - D-ID í†µí•©"""
    logger.info("ğŸ¬ AI ì…ë¡  ì˜ìƒ ìƒì„± ìš”ì²­ ë°›ìŒ")
    
    try:
        data = request.json or {}
        ai_opening_text = data.get('ai_opening_text', 'ê¸°ë³¸ ì…ë¡  í…ìŠ¤íŠ¸')
        debater_gender = data.get('debater_gender', 'male')
        
        if not ai_opening_text or len(ai_opening_text.strip()) < 10:
            ai_opening_text = "í† ë¡  ì£¼ì œì— ëŒ€í•´ ì°¬ì„±í•˜ëŠ” ì…ì¥ì—ì„œ ì˜ê²¬ì„ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
        
        # D-IDë¡œ í† ë¡ ì ì˜ìƒ ìƒì„±
        video_path = generate_avatar_video_unified(
            script=ai_opening_text,
            video_type='debate',
            gender=debater_gender,
            phase='opening'
        )
        
        if video_path and os.path.exists(video_path):
            return send_file(os.path.abspath(video_path), mimetype='video/mp4')
        
        # í´ë°±
        sample_path = generate_sample_video_fallback('debate', 'opening')
        if sample_path and os.path.exists(sample_path):
            return send_file(os.path.abspath(sample_path), mimetype='video/mp4')
        else:
            return Response(b'', mimetype='video/mp4', status=204)
        
    except Exception as e:
        logger.error(f"âŒ AI ì…ë¡  ì˜ìƒ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return Response(b'', mimetype='video/mp4', status=500)

@app.route('/ai/debate/ai-rebuttal-video', methods=['POST'])
def generate_ai_rebuttal_video():
    """AI ë°˜ë¡  ì˜ìƒ ìƒì„± ì—”ë“œí¬ì¸íŠ¸ - D-ID í†µí•©"""
    logger.info("ğŸ¬ AI ë°˜ë¡  ì˜ìƒ ìƒì„± ìš”ì²­ ë°›ìŒ")
    
    try:
        data = request.json or {}
        ai_rebuttal_text = data.get('ai_rebuttal_text', 'ê¸°ë³¸ ë°˜ë¡  í…ìŠ¤íŠ¸')
        debater_gender = data.get('debater_gender', 'male')
        
        video_path = generate_avatar_video_unified(
            script=ai_rebuttal_text,
            video_type='debate',
            gender=debater_gender,
            phase='rebuttal'
        )
        
        if video_path and os.path.exists(video_path):
            return send_file(os.path.abspath(video_path), mimetype='video/mp4')
        
        sample_path = generate_sample_video_fallback('debate', 'rebuttal')
        if sample_path and os.path.exists(sample_path):
            return send_file(os.path.abspath(sample_path), mimetype='video/mp4')
        else:
            return Response(b'', mimetype='video/mp4', status=204)
        
    except Exception as e:
        logger.error(f"âŒ AI ë°˜ë¡  ì˜ìƒ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return Response(b'', mimetype='video/mp4', status=500)

@app.route('/ai/debate/ai-counter-rebuttal-video', methods=['POST'])
def generate_ai_counter_rebuttal_video():
    """AI ì¬ë°˜ë¡  ì˜ìƒ ìƒì„± ì—”ë“œí¬ì¸íŠ¸ - D-ID í†µí•©"""
    logger.info("ğŸ¬ AI ì¬ë°˜ë¡  ì˜ìƒ ìƒì„± ìš”ì²­ ë°›ìŒ")
    
    try:
        data = request.json or {}
        ai_counter_rebuttal_text = data.get('ai_counter_rebuttal_text', 'ê¸°ë³¸ ì¬ë°˜ë¡  í…ìŠ¤íŠ¸')
        debater_gender = data.get('debater_gender', 'male')
        
        video_path = generate_avatar_video_unified(
            script=ai_counter_rebuttal_text,
            video_type='debate',
            gender=debater_gender,
            phase='counter_rebuttal'
        )
        
        if video_path and os.path.exists(video_path):
            return send_file(os.path.abspath(video_path), mimetype='video/mp4')
        
        sample_path = generate_sample_video_fallback('debate', 'counter_rebuttal')
        if sample_path and os.path.exists(sample_path):
            return send_file(os.path.abspath(sample_path), mimetype='video/mp4')
        else:
            return Response(b'', mimetype='video/mp4', status=204)
        
    except Exception as e:
        logger.error(f"âŒ AI ì¬ë°˜ë¡  ì˜ìƒ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return Response(b'', mimetype='video/mp4', status=500)

@app.route('/ai/debate/ai-closing-video', methods=['POST'])
def generate_ai_closing_video():
    """AI ìµœì¢…ë³€ë¡  ì˜ìƒ ìƒì„± ì—”ë“œí¬ì¸íŠ¸ - D-ID í†µí•©"""
    logger.info("ğŸ¬ AI ìµœì¢…ë³€ë¡  ì˜ìƒ ìƒì„± ìš”ì²­ ë°›ìŒ")
    
    try:
        data = request.json or {}
        ai_closing_text = data.get('ai_closing_text', 'ê¸°ë³¸ ìµœì¢…ë³€ë¡  í…ìŠ¤íŠ¸')
        debater_gender = data.get('debater_gender', 'male')
        
        video_path = generate_avatar_video_unified(
            script=ai_closing_text,
            video_type='debate',
            gender=debater_gender,
            phase='closing'
        )
        
        if video_path and os.path.exists(video_path):
            return send_file(os.path.abspath(video_path), mimetype='video/mp4')
        
        sample_path = generate_sample_video_fallback('debate', 'closing')
        if sample_path and os.path.exists(sample_path):
            return send_file(os.path.abspath(sample_path), mimetype='video/mp4')
        else:
            return Response(b'', mimetype='video/mp4', status=204)
        
    except Exception as e:
        logger.error(f"âŒ AI ìµœì¢…ë³€ë¡  ì˜ìƒ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return Response(b'', mimetype='video/mp4', status=500)

@app.route('/ai/debate/<int:debate_id>/opening-video', methods=['POST'])
def process_opening_video(debate_id):
    """ì‚¬ìš©ì ì…ë¡  ì˜ìƒ ì²˜ë¦¬ ì—”ë“œí¬ì¸íŠ¸"""
    return process_debate_video_generic(debate_id, "opening", "rebuttal")

@app.route('/ai/debate/<int:debate_id>/rebuttal-video', methods=['POST'])
def process_rebuttal_video(debate_id):
    """ì‚¬ìš©ì ë°˜ë¡  ì˜ìƒ ì²˜ë¦¬ ì—”ë“œí¬ì¸íŠ¸"""
    return process_debate_video_generic(debate_id, "rebuttal", "counter_rebuttal")

@app.route('/ai/debate/<int:debate_id>/counter-rebuttal-video', methods=['POST'])
def process_counter_rebuttal_video(debate_id):
    """ì‚¬ìš©ì ì¬ë°˜ë¡  ì˜ìƒ ì²˜ë¦¬ ì—”ë“œí¬ì¸íŠ¸"""
    return process_debate_video_generic(debate_id, "counter_rebuttal", "closing")

@app.route('/ai/debate/<int:debate_id>/closing-video', methods=['POST'])
def process_closing_video(debate_id):
    """ì‚¬ìš©ì ìµœì¢…ë³€ë¡  ì˜ìƒ ì²˜ë¦¬ ì—”ë“œí¬ì¸íŠ¸"""
    return process_debate_video_generic(debate_id, "closing", None)

def process_debate_video_generic(debate_id, current_stage, next_ai_stage):
    """í† ë¡  ì˜ìƒ ì²˜ë¦¬ ê³µí†µ í•¨ìˆ˜"""
    logger.info(f"ğŸ“º {current_stage} ì˜ìƒ ì²˜ë¦¬ ìš”ì²­: debate_id={debate_id}")
    
    if 'file' not in request.files and 'video' not in request.files:
        logger.warning("íŒŒì¼ì´ ì œê³µë˜ì§€ ì•ŠìŒ")
        return jsonify(generate_default_debate_response(debate_id, current_stage, next_ai_stage))
    
    file = request.files.get('file') or request.files.get('video')
    
    try:
        temp_path = f"temp_{current_stage}_{debate_id}_{int(time.time())}.mp4"
        file.save(temp_path)
        
        # ì˜¤ë””ì˜¤ ì¶”ì¶œ
        audio_path = extract_audio_from_video(temp_path)
        
        # ìŒì„± ì¸ì‹
        transcription_result = {"text": f"ì‚¬ìš©ìì˜ {current_stage} ë°œì–¸ì…ë‹ˆë‹¤.", "confidence": 0.85}
        if audio_path and WHISPER_AVAILABLE:
            transcription_result = transcribe_with_whisper(audio_path)
        
        # ìŒì„± ë¶„ì„
        audio_analysis = {"voice_stability": 0.8, "fluency_score": 0.85}
        if audio_path and LIBROSA_AVAILABLE:
            audio_analysis = process_audio_with_librosa(audio_path)
        
        # ì–¼êµ´ ë¶„ì„
        facial_analysis = {"confidence": 0.8, "emotion": "ì¤‘ë¦½"}
        if openface_integration:
            try:
                facial_analysis = openface_integration.analyze_video(temp_path)
            except Exception as e:
                logger.warning(f"OpenFace ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        
        # ì¢…í•© ì ìˆ˜ ê³„ì‚°
        scores = calculate_debate_scores(transcription_result, audio_analysis, facial_analysis)
        
        # ê²°ê³¼ êµ¬ì„±
        result = {
            f"user_{current_stage}_text": transcription_result.get("text", ""),
            **scores
        }
        
        # ë‹¤ìŒ AI ì‘ë‹µ ìƒì„±
        if next_ai_stage:
            topic = request.form.get("topic", "í† ë¡  ì£¼ì œ")
            user_text = transcription_result.get("text", "")
            
            if llm_module:
                try:
                    llm_result = llm_module.analyze_user_response_and_generate_rebuttal(
                        user_text, facial_analysis, audio_analysis, next_ai_stage
                    )
                    ai_response = llm_result.get("ai_response", "")
                    result[f"ai_{next_ai_stage}_text"] = ai_response
                except Exception as e:
                    logger.error(f"LLM ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}")
                    result[f"ai_{next_ai_stage}_text"] = get_fallback_ai_response(next_ai_stage, topic, user_text)
            else:
                result[f"ai_{next_ai_stage}_text"] = get_fallback_ai_response(next_ai_stage, topic, user_text)
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        cleanup_temp_files([temp_path, audio_path])
        
        logger.info(f"âœ… {current_stage} ì˜ìƒ ì²˜ë¦¬ ì™„ë£Œ")
        return jsonify(result)
        
    except Exception as e:
        cleanup_temp_files([temp_path])
        error_msg = f"{current_stage} ì˜ìƒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        logger.error(error_msg)
        return jsonify(generate_default_debate_response(debate_id, current_stage, next_ai_stage)), 200

def calculate_debate_scores(transcription: Dict, audio: Dict, facial: Dict) -> Dict[str, Any]:
    """í† ë¡  ì ìˆ˜ ê³„ì‚°"""
    try:
        text = transcription.get("text", "")
        confidence = transcription.get("confidence", 0.85)
        voice_stability = audio.get("voice_stability", 0.8)
        fluency = audio.get("fluency_score", 0.85)
        facial_confidence = facial.get("confidence", 0.8)
        
        # ì ìˆ˜ ê³„ì‚° (ì†Œìˆ˜ì  í•œ ìë¦¬)
        scores = {
            "initiative_score": round(min(5.0, 3.0 + confidence), 1),
            "collaborative_score": round(min(5.0, 3.0 + (len(text.split()) / 100)), 1),
            "communication_score": round(min(5.0, 3.0 + fluency), 1),
            "logic_score": round(min(5.0, 3.0 + calculate_logic_score(text)), 1),
            "problem_solving_score": round(min(5.0, 3.0 + calculate_problem_solving_score(text)), 1),
            "voice_score": round(min(5.0, voice_stability * 5), 1),
            "action_score": round(min(5.0, facial_confidence * 5), 1)
        }
        
        # í”¼ë“œë°± ìƒì„±
        for category in ["initiative", "collaborative", "communication", "logic", "problem_solving"]:
            score = scores[f"{category}_score"]
            if score >= 4.5:
                scores[f"{category}_feedback"] = f"{get_korean_name(category)}: ë§¤ìš° ìš°ìˆ˜"
            elif score >= 4.0:
                scores[f"{category}_feedback"] = f"{get_korean_name(category)}: ìš°ìˆ˜"
            elif score >= 3.5:
                scores[f"{category}_feedback"] = f"{get_korean_name(category)}: ì–‘í˜¸"
            else:
                scores[f"{category}_feedback"] = f"{get_korean_name(category)}: ê°œì„  í•„ìš”"
        
        # ì¢…í•© í”¼ë“œë°±
        avg_score = sum(scores[k] for k in scores if k.endswith("_score")) / 7
        if avg_score >= 4.5:
            scores["feedback"] = "ë§¤ìš° ìš°ìˆ˜í•œ í† ë¡  ìˆ˜í–‰ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤."
        elif avg_score >= 4.0:
            scores["feedback"] = "ìš°ìˆ˜í•œ í† ë¡  ìˆ˜í–‰ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤."
        elif avg_score >= 3.5:
            scores["feedback"] = "ì–‘í˜¸í•œ í† ë¡  ìˆ˜í–‰ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤."
        else:
            scores["feedback"] = "í† ë¡  ìˆ˜í–‰ì— ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤."
        
        scores["sample_answer"] = "êµ¬ì²´ì ì¸ ê·¼ê±°ì™€ ì˜ˆì‹œë¥¼ ë“¤ì–´ ë…¼ë¦¬ì ìœ¼ë¡œ ì„¤ëª…í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤."
        
        return scores
        
    except Exception as e:
        logger.error(f"í† ë¡  ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
        return get_default_debate_scores()

def calculate_logic_score(text: str) -> float:
    """ë…¼ë¦¬ì„± ì ìˆ˜ ê³„ì‚°"""
    logic_indicators = ["ë”°ë¼ì„œ", "ê·¸ëŸ¬ë¯€ë¡œ", "ê²°ë¡ ì ìœ¼ë¡œ", "ì™œëƒí•˜ë©´", "ê·¼ê±°ëŠ”", "ì˜ˆë¥¼ ë“¤ì–´"]
    logic_count = sum(1 for indicator in logic_indicators if indicator in text)
    return min(1.0, logic_count * 0.3)

def calculate_problem_solving_score(text: str) -> float:
    """ë¬¸ì œí•´ê²° ì ìˆ˜ ê³„ì‚°"""
    problem_solving_indicators = ["í•´ê²°", "ë°©ì•ˆ", "ëŒ€ì•ˆ", "ê°œì„ ", "ì „ëµ", "ì ‘ê·¼"]
    problem_count = sum(1 for indicator in problem_solving_indicators if indicator in text)
    return min(1.0, problem_count * 0.3)

def get_korean_name(category: str) -> str:
    """ì¹´í…Œê³ ë¦¬ í•œê¸€ëª… ë°˜í™˜"""
    mapping = {
        "initiative": "ì ê·¹ì„±",
        "collaborative": "í˜‘ë ¥ì„±",
        "communication": "ì˜ì‚¬ì†Œí†µ",
        "logic": "ë…¼ë¦¬ì„±",
        "problem_solving": "ë¬¸ì œí•´ê²°"
    }
    return mapping.get(category, category)

def get_default_debate_scores() -> Dict[str, Any]:
    """ê¸°ë³¸ í† ë¡  ì ìˆ˜"""
    return {
        "initiative_score": 3.5,
        "collaborative_score": 3.2,
        "communication_score": 3.8,
        "logic_score": 3.3,
        "problem_solving_score": 3.5,
        "voice_score": 3.7,
        "action_score": 3.9,
        "initiative_feedback": "ì ê·¹ì„±: ë³´í†µ",
        "collaborative_feedback": "í˜‘ë ¥ì„±: ë³´í†µ",
        "communication_feedback": "ì˜ì‚¬ì†Œí†µ: ì–‘í˜¸",
        "logic_feedback": "ë…¼ë¦¬ì„±: ë³´í†µ",
        "problem_solving_feedback": "ë¬¸ì œí•´ê²°: ë³´í†µ",
        "feedback": "ì „ë°˜ì ìœ¼ë¡œ ì–‘í˜¸í•œ ìˆ˜í–‰ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.",
        "sample_answer": "êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ ê·¼ê±°ë¥¼ ë“¤ì–´ ë…¼ë¦¬ì ìœ¼ë¡œ ì„¤ëª…í•´ë³´ì„¸ìš”."
    }

def generate_default_debate_response(debate_id: int, stage: str, next_stage: Optional[str]) -> Dict:
    """ê¸°ë³¸ í† ë¡  ì‘ë‹µ ìƒì„±"""
    response = {
        f"user_{stage}_text": "íŒŒì¼ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
        **get_default_debate_scores()
    }
    
    if next_stage:
        response[f"ai_{next_stage}_text"] = f"ê¸°ë³¸ AI {next_stage} ì‘ë‹µì…ë‹ˆë‹¤."
    
    return response

def get_fallback_ai_response(stage: str, topic: str = "í† ë¡  ì£¼ì œ", user_text: str = "") -> str:
    """í´ë°± AI ì‘ë‹µ"""
    responses = {
        "rebuttal": f"ë§ì”€í•˜ì‹  {topic}ì— ëŒ€í•œ ì˜ê²¬ì„ ê²½ì²­í–ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ë‹¤ë¥¸ ê´€ì ì—ì„œ ë³´ë©´ ëª‡ ê°€ì§€ ê³ ë ¤í•´ì•¼ í•  ì ë“¤ì´ ìˆìŠµë‹ˆë‹¤.",
        "counter_rebuttal": f"ì œê¸°í•˜ì‹  ì ë“¤ì„ ì¶©ë¶„íˆ ì´í•´í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ {topic}ì˜ ì¥ê¸°ì  ê´€ì ì—ì„œ ë³´ë©´ ì—¬ì „íˆ ì‹ ì¤‘í•œ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤.",
        "closing": f"ê²°ë¡ ì ìœ¼ë¡œ {topic}ì— ëŒ€í•œ ì´ë²ˆ í† ë¡ ì„ í†µí•´ ë‹¤ì–‘í•œ ê´€ì ì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ê· í˜•ì¡íŒ ì‹œê°ì´ ì¤‘ìš”í•˜ë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤."
    }
    
    return responses.get(stage, f"{topic}ì— ëŒ€í•´ ì˜ê²¬ì„ ë‚˜ëˆ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.")

# ==================== ì¶”ê°€ ìœ í‹¸ë¦¬í‹° ì—”ë“œí¬ì¸íŠ¸ ====================

@app.route('/videos/<path:filename>')
def serve_video(filename):
    """ì˜ìƒ íŒŒì¼ ì œê³µ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        video_path = os.path.join('videos', filename)
        if os.path.exists(video_path):
            return send_file(video_path, mimetype='video/mp4')
        else:
            logger.error(f"ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {video_path}")
            return Response(b'Video not found', status=404)
    except Exception as e:
        logger.error(f"ì˜ìƒ íŒŒì¼ ì œê³µ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return Response(b'Error serving video', status=500)

@app.route('/ai/jobs/recommend-tfidf', methods=['POST'])
def recommend_jobs_tfidf():
    """TF-IDF ê¸°ë°˜ ê³µê³  ì¶”ì²œ ì—”ë“œí¬ì¸íŠ¸"""
    if not TFIDF_RECOMMENDATION_AVAILABLE:
        return jsonify({"error": "TF-IDF ê³µê³ ì¶”ì²œ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 500
    
    try:
        data = request.json or {}
        logger.info(f"TF-IDF ê³µê³  ì¶”ì²œ ìš”ì²­ ë°›ìŒ: {data}")
        
        if 'skills' in data:
            skills = data['skills']
            limit = data.get('limit', 10)
            result = tfidf_recommendation_module.get_recommendations_by_skills(skills, limit)
            return jsonify(result)
        
        elif 'profile' in data:
            profile = data['profile']
            limit = data.get('limit', 10)
            result = tfidf_recommendation_module.get_recommendations_by_profile(profile, limit)
            return jsonify(result)
        
        else:
            return jsonify({"error": "skills ë˜ëŠ” profile ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400
            
    except Exception as e:
        logger.error(f"TF-IDF ê³µê³  ì¶”ì²œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/ai/jobs/rare-skills', methods=['GET'])
def get_rare_skills():
    """í¬ì†Œ ê¸°ìˆ  ì •ë³´ ì¡°íšŒ ì—”ë“œí¬ì¸íŠ¸"""
    if not TFIDF_RECOMMENDATION_AVAILABLE:
        return jsonify({"error": "TF-IDF ê³µê³ ì¶”ì²œ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 500
    
    try:
        result = tfidf_recommendation_module.get_rare_skills_info()
        return jsonify(result)
    except Exception as e:
        logger.error(f"í¬ì†Œ ê¸°ìˆ  ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/ai/health', methods=['GET'])
def health_check():
    """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ (AWS ALBìš©)"""
    return jsonify({"status": "healthy", "timestamp": time.time()})

# ==================== ë©”ì¸ ì‹¤í–‰ ====================

if __name__ == "__main__":
    print("=" * 80)
    print("ğŸš€ VeriView AI ë©”ì¸ ì„œë²„ ì‹œì‘ - ì™„ì „ í†µí•© ë²„ì „")
    print("=" * 80)
    
    # D-ID ì´ˆê¸°í™”
    if initialize_d_id():
        print("âœ… D-ID í†µí•© ì„±ê³µ")
    else:
        print("âš ï¸ D-ID í†µí•© ì‹¤íŒ¨ - í´ë°± ëª¨ë“œ ì‚¬ìš©")
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    if initialize_analyzers():
        print("âœ… ë¶„ì„ê¸° ì´ˆê¸°í™” ì„±ê³µ")
    else:
        print("âš ï¸ ë¶„ì„ê¸° ì´ˆê¸°í™” ë¶€ë¶„ ì‹¤íŒ¨")
    
    # AI ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    initialize_ai_systems()
    
    print("-" * 80)
    print("ğŸ“ ì„œë²„ ì£¼ì†Œ: http://localhost:5000")
    print("ğŸ” í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸: http://localhost:5000/ai/test")
    print("-" * 80)
    print("ğŸ”§ í™œì„±í™”ëœ ëª¨ë“ˆ:")
    print(f"  - D-ID API: {'âœ…' if did_initialized else 'âŒ'}")
    print(f"  - LLM (Gemma3:12b): {'âœ…' if llm_module else 'âŒ'}")
    print(f"  - OpenFace: {'âœ…' if openface_integration else 'âŒ'}")
    print(f"  - Whisper: {'âœ…' if WHISPER_AVAILABLE else 'âŒ'}")
    print(f"  - TTS: {'âœ…' if TTS_AVAILABLE else 'âŒ'}")
    print(f"  - Librosa: {'âœ…' if LIBROSA_AVAILABLE else 'âŒ'}")
    print(f"  - ê³µê³ ì¶”ì²œ: {'âœ…' if JOB_RECOMMENDATION_AVAILABLE else 'âŒ'}")
    print(f"  - TF-IDF ì¶”ì²œ: {'âœ…' if TFIDF_RECOMMENDATION_AVAILABLE else 'âŒ'}")
    print("=" * 80)
    
    # ì£¼ì˜ì‚¬í•­ ì¶œë ¥
    if not os.environ.get('D_ID_API_KEY'):
        print("âš ï¸  ì£¼ì˜: D_ID_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”!")
        print("   export D_ID_API_KEY='your_api_key_here'")
    
    print("\nì„œë²„ë¥¼ ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.\n")
    
    # Flask ì•± ì‹¤í–‰
    app.run(host="0.0.0.0", port=5000, debug=False)
