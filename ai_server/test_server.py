#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
VeriView AI ì„œë²„ - í…ŒìŠ¤íŠ¸ ì„œë²„ (LLM ì œì™¸)
OpenFace2.0, Whisper, TTS, Librosa ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë˜ LLM ëŒ€ì‹  ê³ ì •ëœ ì‘ë‹µì„ ë°˜í™˜í•˜ëŠ” í…ŒìŠ¤íŠ¸ ì„œë²„

ì‹¤í–‰ ë°©ë²•: python test_server.py
í¬íŠ¸: 5000
"""
from flask import Flask, jsonify, request, send_file
from flask_cors import CORS
import os
import tempfile
import logging
import time
import json
from typing import Dict, Any, Optional

# í…ŒìŠ¤íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from test_features.debate.main import DebateTestMain
    from test_features.personal_interview.main import PersonalInterviewTestMain
    DEBATE_MODULE_AVAILABLE = True
    PERSONAL_INTERVIEW_MODULE_AVAILABLE = True
    print("âœ… í…ŒìŠ¤íŠ¸ ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ: í† ë¡ ë©´ì ‘ ë° ê°œì¸ë©´ì ‘ ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥")
except ImportError as e:
    print(f"âŒ í…ŒìŠ¤íŠ¸ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    DEBATE_MODULE_AVAILABLE = False
    PERSONAL_INTERVIEW_MODULE_AVAILABLE = False

# ê³µí†µ ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from job_recommendation_module import JobRecommendationModule
    job_recommendation_module = JobRecommendationModule()
    JOB_RECOMMENDATION_AVAILABLE = True
    print("âœ… ê³µê³ ì¶”ì²œ ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"âŒ ê³µê³ ì¶”ì²œ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    JOB_RECOMMENDATION_AVAILABLE = False
    job_recommendation_module = None

# ê°œë³„ ëª¨ë“ˆ ì„í¬íŠ¸ (LLM ì œì™¸)
try:
    import whisper
    import librosa
    import soundfile as sf
    WHISPER_AVAILABLE = True
    LIBROSA_AVAILABLE = True
    print("âœ… Whisper ë° Librosa ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ ìŒì„± ë¶„ì„ ëª¨ë“ˆ ì¼ë¶€ ì œí•œ: {e}")
    WHISPER_AVAILABLE = False
    LIBROSA_AVAILABLE = False

# TTS ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from TTS.api import TTS
    TTS_AVAILABLE = True
    print("âœ… TTS ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ TTS ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    TTS_AVAILABLE = False

# OpenFace ëª¨ë“ˆ ì„í¬íŠ¸ (ì‹¤ì œ ëª¨ë“ˆ - LLM ì œì™¸)
try:
    from test_features.debate.openface_module import OpenFaceTestModule
    OPENFACE_AVAILABLE = True
    print("âœ… OpenFace í…ŒìŠ¤íŠ¸ ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ OpenFace ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    OPENFACE_AVAILABLE = False

# Flask ì•± ì´ˆê¸°í™”
app = Flask(__name__)
CORS(app)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# ì „ì—­ ë³€ìˆ˜ë¡œ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” (LLM ì œì™¸)
debate_test_system = None
personal_interview_test_system = None
openface_test_module = None
whisper_model = None
tts_model = None

def initialize_test_systems():
    """í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” (LLM ì œì™¸)"""
    global debate_test_system, personal_interview_test_system, openface_test_module
    global whisper_model, tts_model
    
    try:
        # í† ë¡ ë©´ì ‘ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        if DEBATE_MODULE_AVAILABLE:
            debate_test_system = DebateTestMain()
            logger.info("í† ë¡ ë©´ì ‘ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ê°œì¸ë©´ì ‘ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        if PERSONAL_INTERVIEW_MODULE_AVAILABLE:
            personal_interview_test_system = PersonalInterviewTestMain()
            logger.info("ê°œì¸ë©´ì ‘ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # OpenFace í…ŒìŠ¤íŠ¸ ëª¨ë“ˆ ì´ˆê¸°í™”
        if OPENFACE_AVAILABLE:
            openface_test_module = OpenFaceTestModule()
            logger.info("OpenFace í…ŒìŠ¤íŠ¸ ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # Whisper ëª¨ë¸ ì´ˆê¸°í™”
        if WHISPER_AVAILABLE:
            whisper_model = whisper.load_model("base")
            logger.info("Whisper ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # TTS ëª¨ë¸ ì´ˆê¸°í™”
        if TTS_AVAILABLE:
            tts_model = TTS(model_name="tts_models/en/ljspeech/tacotron2-DDC")
            logger.info("TTS ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
                
    except Exception as e:
        logger.error(f"í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")

def process_audio_with_librosa(audio_path: str) -> Dict[str, Any]:
    """Librosaë¥¼ ì‚¬ìš©í•œ ì˜¤ë””ì˜¤ ë¶„ì„"""
    if not LIBROSA_AVAILABLE:
        return get_default_audio_analysis()
    
    try:
        y, sr = librosa.load(audio_path)
        
        # ê¸°ë³¸ ìŒì„± íŠ¹ì„± ì¶”ì¶œ
        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
        spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
        spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]
        zero_crossing_rate = librosa.feature.zero_crossing_rate(y)[0]
        
        # í‰ê· ê°’ ê³„ì‚°
        analysis_result = {
            "mfcc_mean": float(mfccs.mean()),
            "spectral_centroid_mean": float(spectral_centroids.mean()),
            "spectral_rolloff_mean": float(spectral_rolloff.mean()),
            "zero_crossing_rate_mean": float(zero_crossing_rate.mean()),
            "duration": float(len(y) / sr),
            "sample_rate": int(sr),
            "voice_stability": min(1.0, max(0.0, 1.0 - abs(spectral_centroids.std() / spectral_centroids.mean()))),
            "speaking_rate_wpm": estimate_speaking_rate(y, sr),
            "volume_consistency": calculate_volume_consistency(y),
            "fluency_score": calculate_fluency_score(y, sr)
        }
        
        return analysis_result
        
    except Exception as e:
        logger.error(f"Librosa ì˜¤ë””ì˜¤ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return get_default_audio_analysis()

def get_default_audio_analysis():
    """ê¸°ë³¸ ì˜¤ë””ì˜¤ ë¶„ì„ ê²°ê³¼"""
    return {
        "voice_stability": 0.8,
        "speaking_rate_wpm": 120,
        "volume_consistency": 0.75,
        "fluency_score": 0.85,
        "duration": 30.0,
        "sample_rate": 16000,
        "analysis_method": "default"
    }

def estimate_speaking_rate(audio_data, sample_rate):
    """ë§í•˜ê¸° ì†ë„ ì¶”ì •"""
    try:
        frame_length = int(0.025 * sample_rate)
        hop_length = int(0.01 * sample_rate)
        
        energy = librosa.feature.rms(y=audio_data, frame_length=frame_length, hop_length=hop_length)[0]
        energy_threshold = energy.mean() * 0.3
        
        speech_frames = len(energy[energy > energy_threshold])
        speech_duration = speech_frames * hop_length / sample_rate
        
        estimated_wpm = max(60, min(200, (speech_duration / 60) * 150))
        return estimated_wpm
    except Exception:
        return 120

def calculate_volume_consistency(audio_data):
    """ìŒëŸ‰ ì¼ê´€ì„± ê³„ì‚°"""
    try:
        frame_length = 2048
        hop_length = 512
        rms_energy = librosa.feature.rms(y=audio_data, frame_length=frame_length, hop_length=hop_length)[0]
        consistency = 1.0 - min(1.0, rms_energy.std() / (rms_energy.mean() + 1e-8))
        return max(0.0, consistency)
    except Exception:
        return 0.5

def calculate_fluency_score(audio_data, sample_rate):
    """ë°œí™” ìœ ì°½ì„± ì ìˆ˜ ê³„ì‚°"""
    try:
        frame_length = int(0.025 * sample_rate)
        hop_length = int(0.01 * sample_rate)
        
        energy = librosa.feature.rms(y=audio_data, frame_length=frame_length, hop_length=hop_length)[0]
        silence_threshold = energy.mean() * 0.1
        
        silence_ratio = len(energy[energy < silence_threshold]) / len(energy)
        fluency_score = 1.0 - min(1.0, silence_ratio * 2)
        return max(0.0, fluency_score)
    except Exception:
        return 0.5

def transcribe_with_whisper(audio_path: str) -> Dict[str, Any]:
    """Whisperë¥¼ ì‚¬ìš©í•œ ìŒì„± ì¸ì‹"""
    if not WHISPER_AVAILABLE or whisper_model is None:
        return get_default_transcription()
    
    try:
        result = whisper_model.transcribe(audio_path, language="ko")
        
        return {
            "text": result["text"],
            "language": result["language"],
            "segments": result["segments"][:3],
            "confidence": calculate_transcription_confidence(result)
        }
        
    except Exception as e:
        logger.error(f"Whisper ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {str(e)}")
        return get_default_transcription()

def get_default_transcription():
    """ê¸°ë³¸ ìŒì„± ì¸ì‹ ê²°ê³¼"""
    return {
        "text": "ìŒì„± ì¸ì‹ ê²°ê³¼ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.",
        "language": "ko",
        "confidence": 0.85,
        "analysis_method": "default"
    }

def calculate_transcription_confidence(whisper_result):
    """Whisper ê²°ê³¼ì˜ ì‹ ë¢°ë„ ê³„ì‚°"""
    try:
        if "segments" in whisper_result and whisper_result["segments"]:
            total_confidence = 0
            total_segments = 0
            
            for segment in whisper_result["segments"]:
                if "avg_logprob" in segment:
                    confidence = max(0, min(1, (segment["avg_logprob"] + 1) / 1))
                    total_confidence += confidence
                    total_segments += 1
            
            if total_segments > 0:
                return total_confidence / total_segments
        
        return 0.75
    except Exception:
        return 0.75

def synthesize_with_tts(text: str, output_path: str) -> Optional[str]:
    """TTSë¥¼ ì‚¬ìš©í•œ ìŒì„± í•©ì„±"""
    if not TTS_AVAILABLE or tts_model is None:
        logger.warning("TTS ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    try:
        if len(text) > 500:
            text = text[:500] + "..."
        
        tts_model.tts_to_file(text=text, file_path=output_path)
        
        if os.path.exists(output_path):
            return output_path
        else:
            return None
    except Exception as e:
        logger.error(f"TTS ìŒì„± í•©ì„± ì˜¤ë¥˜: {str(e)}")
        return None

def extract_audio_from_video(video_path: str) -> Optional[str]:
    """ë¹„ë””ì˜¤ì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ"""
    try:
        import subprocess
        
        audio_path = video_path.replace('.mp4', '_audio.wav').replace('.webm', '_audio.wav')
        
        command = [
            'ffmpeg', '-i', video_path, '-acodec', 'pcm_s16le', 
            '-ac', '1', '-ar', '16000', audio_path, '-y'
        ]
        
        subprocess.run(command, check=True, capture_output=True)
        
        if os.path.exists(audio_path):
            return audio_path
        else:
            return None
    except Exception as e:
        logger.error(f"ì˜¤ë””ì˜¤ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
        return None

def analyze_with_openface(video_path: str) -> Dict[str, Any]:
    """OpenFaceë¥¼ ì‚¬ìš©í•œ ì–¼êµ´ ë¶„ì„"""
    if not OPENFACE_AVAILABLE or openface_test_module is None:
        return get_default_facial_analysis()
    
    try:
        return openface_test_module.analyze_video(video_path)
    except Exception as e:
        logger.error(f"OpenFace ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return get_default_facial_analysis()

def get_default_facial_analysis():
    """ê¸°ë³¸ ì–¼êµ´ ë¶„ì„ ê²°ê³¼"""
    return {
        "confidence": 0.8,
        "emotion": "ì¤‘ë¦½",
        "gaze_stability": 0.75,
        "facial_expressions": "ì•ˆì •ì ",
        "analysis_method": "default"
    }

def cleanup_temp_files(file_paths: list):
    """ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
    for file_path in file_paths:
        if file_path and os.path.exists(file_path):
            try:
                os.remove(file_path)
            except Exception as e:
                logger.warning(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {file_path} - {str(e)}")

# ê³ ì • ì‘ë‹µ ìƒì„± í•¨ìˆ˜ë“¤
def get_fixed_ai_response(stage: str, topic: str = "ì¸ê³µì§€ëŠ¥", user_text: str = None) -> str:
    """í† ë¡  ë‹¨ê³„ë³„ ê³ ì • AI ì‘ë‹µ ìƒì„±"""
    responses = {
        "opening": f"{topic}ì˜ ë°œì „ì€ ì¸ë¥˜ì—ê²Œ ê¸ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹  ê²ƒì…ë‹ˆë‹¤. íš¨ìœ¨ì„± ì¦ëŒ€ì™€ ìƒˆë¡œìš´ ê°€ëŠ¥ì„±ì„ ì œê³µí•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.",
        "rebuttal": f"ë§ì”€í•˜ì‹  ìš°ë ¤ì‚¬í•­ë„ ìˆì§€ë§Œ, {topic}ì˜ ì¥ì ì´ ë” í¬ë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤. ì ì ˆí•œ ê·œì œì™€ í•¨ê»˜ ë°œì „ì‹œì¼œ ë‚˜ê°€ë©´ ë  ê²ƒì…ë‹ˆë‹¤.",
        "counter_rebuttal": f"ê·œì œë§Œìœ¼ë¡œëŠ” í•œê³„ê°€ ìˆì„ ìˆ˜ ìˆì§€ë§Œ, {topic} ê¸°ìˆ  ìì²´ì˜ ë°œì „ì„ í†µí•´ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "closing": f"ê²°ë¡ ì ìœ¼ë¡œ {topic}ì€ ì¸ë¥˜ì˜ ë¯¸ë˜ë¥¼ ìœ„í•œ í•„ìˆ˜ì ì¸ ê¸°ìˆ ì…ë‹ˆë‹¤. ì‹ ì¤‘í•œ ì ‘ê·¼ê³¼ í•¨ê»˜ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•´ì•¼ í•©ë‹ˆë‹¤."
    }
    return responses.get(stage, f"{topic}ì— ëŒ€í•œ ì˜ê²¬ì„ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.")

def get_fixed_interview_question(question_type: str) -> str:
    """ë©´ì ‘ ì§ˆë¬¸ ìœ í˜•ë³„ ê³ ì • ì§ˆë¬¸ ìƒì„±"""
    questions = {
        "general": "ìì‹ ì˜ ì¥ì ê³¼ ë‹¨ì ì— ëŒ€í•´ êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ í•¨ê»˜ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "technical": "ë³¸ì¸ì´ ê°€ì¥ ìì‹ ìˆì–´í•˜ëŠ” ê¸°ìˆ  ë¶„ì•¼ëŠ” ë¬´ì—‡ì´ë©°, ê·¸ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
        "behavioral": "íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ê°ˆë“±ì´ ë°œìƒí–ˆì„ ë•Œ ì–´ë–»ê²Œ í•´ê²°í–ˆëŠ”ì§€ êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¡œ ë§ì”€í•´ì£¼ì„¸ìš”.",
        "fit": "ìš°ë¦¬ íšŒì‚¬ì— ì§€ì›í•˜ê²Œ ëœ ë™ê¸°ì™€ ë³¸ì¸ì´ ê¸°ì—¬í•  ìˆ˜ ìˆëŠ” ë¶€ë¶„ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "personality": "ë³¸ì¸ì˜ ì„±ê²© ì¤‘ ê°€ì¥ í° ì¥ì ê³¼ ë‹¨ì ì€ ë¬´ì—‡ì¸ê°€ìš”?"
    }
    return questions.get(question_type, "ë³¸ì¸ì— ëŒ€í•´ ê°„ë‹¨íˆ ì†Œê°œí•´ì£¼ì„¸ìš”.")

# ==================== API ì—”ë“œí¬ì¸íŠ¸ ====================

@app.route('/ai/health', methods=['GET'])
def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return jsonify({
        "status": "healthy",
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "server_type": "test_server",
        "services": {
            "debate": DEBATE_MODULE_AVAILABLE,
            "personal_interview": PERSONAL_INTERVIEW_MODULE_AVAILABLE,
            "openface": OPENFACE_AVAILABLE,
            "whisper": WHISPER_AVAILABLE,
            "tts": TTS_AVAILABLE,
            "librosa": LIBROSA_AVAILABLE,
            "job_recommendation": JOB_RECOMMENDATION_AVAILABLE
        },
        "note": "LLM ëª¨ë“ˆì€ ì œì™¸ë¨ (ê³ ì • ì‘ë‹µ ì‚¬ìš©)"
    })

@app.route('/ai/test', methods=['GET'])
def test_connection():
    """ì—°ê²° í…ŒìŠ¤íŠ¸ ë° ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸"""
    logger.info("ì—°ê²° í…ŒìŠ¤íŠ¸ ìš”ì²­ ë°›ìŒ: /ai/test")
    
    # ë°±ì—”ë“œ ì—°ê²° í…ŒìŠ¤íŠ¸
    backend_status = "ì—°ê²° í™•ì¸ í•„ìš”"
    try:
        import requests
        response = requests.get("http://localhost:4000/api/test", timeout=2)
        if response.status_code == 200:
            backend_status = "ì—°ê²°ë¨ (ì •ìƒ ì‘ë™)"
        else:
            backend_status = f"ì—°ê²°ë¨ (ìƒíƒœ ì½”ë“œ: {response.status_code})"
    except Exception as e:
        backend_status = f"ì—°ê²° ì‹¤íŒ¨: {str(e)}"
    
    test_response = {
        "status": "AI í…ŒìŠ¤íŠ¸ ì„œë²„ê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.",
        "server_type": "test_server (LLM ì œì™¸, ê³ ì • ì‘ë‹µ ì‚¬ìš©)",
        "backend_connection": backend_status,
        "modules": {
            "debate_test": "ì‚¬ìš© ê°€ëŠ¥" if DEBATE_MODULE_AVAILABLE else "ì‚¬ìš© ë¶ˆê°€",
            "personal_interview_test": "ì‚¬ìš© ê°€ëŠ¥" if PERSONAL_INTERVIEW_MODULE_AVAILABLE else "ì‚¬ìš© ë¶ˆê°€",
            "openface": "ì‚¬ìš© ê°€ëŠ¥" if OPENFACE_AVAILABLE else "ì‚¬ìš© ë¶ˆê°€",
            "whisper": "ì‚¬ìš© ê°€ëŠ¥" if WHISPER_AVAILABLE else "ì‚¬ìš© ë¶ˆê°€",
            "tts": "ì‚¬ìš© ê°€ëŠ¥" if TTS_AVAILABLE else "ì‚¬ìš© ë¶ˆê°€",
            "librosa": "ì‚¬ìš© ê°€ëŠ¥" if LIBROSA_AVAILABLE else "ì‚¬ìš© ë¶ˆê°€",
            "job_recommendation": "ì‚¬ìš© ê°€ëŠ¥" if JOB_RECOMMENDATION_AVAILABLE else "ì‚¬ìš© ë¶ˆê°€"
        },
        "endpoints": {
            "debate": {
                "ai_opening": "/ai/debate/<debate_id>/ai-opening",
                "opening_video": "/ai/debate/<debate_id>/opening-video",
                "rebuttal_video": "/ai/debate/<debate_id>/rebuttal-video",
                "counter_rebuttal_video": "/ai/debate/<debate_id>/counter-rebuttal-video",
                "closing_video": "/ai/debate/<debate_id>/closing-video"
            },
            "personal_interview": {
                "start": "/ai/interview/start",  
                "question": "/ai/interview/<interview_id>/question",
                "answer_video": "/ai/interview/<interview_id>/answer-video"
            },
            "job_recommendation": {
                "recommend": "/ai/jobs/recommend",
                "categories": "/ai/jobs/categories",
                "recruitment_posting": "/ai/recruitment/posting"
            }
        },
        "mode": "í…ŒìŠ¤íŠ¸ ëª¨ë“œ (LLM ì œì™¸, ë‹¤ë¥¸ AI ëª¨ë“ˆ ì‚¬ìš© + ê³ ì • ì‘ë‹µ)",
        "note": "ì‹¤ì œ OpenFace, Whisper, TTS, Librosa ëª¨ë“ˆì„ ì‚¬ìš©í•˜ë˜ LLM ëŒ€ì‹  ê³ ì • ì‘ë‹µ ë°˜í™˜"
    }
    
    logger.info(f"í…ŒìŠ¤íŠ¸ ì‘ë‹µ: {test_response}")
    return jsonify(test_response)

# ==================== ê³µê³ ì¶”ì²œ API ì—”ë“œí¬ì¸íŠ¸ ====================

@app.route('/ai/recruitment/posting', methods=['POST'])
def recruitment_posting():
    """ë°±ì—”ë“œ ì—°ë™ìš© ê³µê³ ì¶”ì²œ ì—”ë“œí¬ì¸íŠ¸"""
    if not JOB_RECOMMENDATION_AVAILABLE:
        return jsonify({"error": "ê³µê³ ì¶”ì²œ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 500
    
    try:
        data = request.json or {}
        logger.info(f"ë°±ì—”ë“œ ê³µê³ ì¶”ì²œ ìš”ì²­ ë°›ìŒ: {data}")
        
        category = data.get('category', 'ICT')
        
        # ê³µê³ ì¶”ì²œ ëª¨ë“ˆë¡œ ì¶”ì²œ ìƒì„±
        recommendations = job_recommendation_module.get_recommendations_by_category(category, 10)
        
        if recommendations.get('status') == 'success':
            posting_list = []
            
            base_ids = {
                'ICT': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
                'BM': [1, 2, 3, 4, 5],
                'SM': [1, 2, 3, 4, 5]
            }
            
            category_ids = base_ids.get(category, base_ids['ICT'])
            
            for i, job in enumerate(recommendations.get('recommendations', [])):
                job_posting_id = category_ids[i % len(category_ids)]
                
                posting_list.append({
                    "job_posting_id": job_posting_id,
                    "title": job.get('title', ''),
                    "keyword": ', '.join(job.get('keywords', [])),
                    "corporation": job.get('company', '')
                })
            
            response = {"posting": posting_list}
            logger.info(f"ë°±ì—”ë“œ ê³µê³ ì¶”ì²œ ì‘ë‹µ: {len(posting_list)}ê°œ ê³µê³ ")
            return jsonify(response)
        else:
            return jsonify({"error": "ì¶”ì²œ ìƒì„± ì‹¤íŒ¨"}), 500
            
    except Exception as e:
        error_msg = f"ë°±ì—”ë“œ ê³µê³ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        logger.error(error_msg)
        return jsonify({"error": error_msg}), 500

@app.route('/ai/jobs/recommend', methods=['POST'])
def recommend_jobs():
    """ê³µê³  ì¶”ì²œ ì—”ë“œí¬ì¸íŠ¸"""
    if not JOB_RECOMMENDATION_AVAILABLE:
        return jsonify({"error": "ê³µê³ ì¶”ì²œ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 500
    
    try:
        data = request.json or {}
        logger.info(f"ê³µê³  ì¶”ì²œ ìš”ì²­ ë°›ìŒ: {data}")
        
        if 'interview_scores' in data:
            interview_scores = data['interview_scores']
            limit = data.get('limit', 10)
            result = job_recommendation_module.get_recommendations_by_interview_result(interview_scores, limit)
            return jsonify(result)
        elif 'category' in data:
            category = data['category']
            limit = data.get('limit', 10)
            result = job_recommendation_module.get_recommendations_by_category(category, limit)
            return jsonify(result)
        else:
            result = job_recommendation_module.get_recommendations_by_category("ICT", 10)
            return jsonify(result)
            
    except Exception as e:
        error_msg = f"ê³µê³  ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        logger.error(error_msg)
        return jsonify({"error": error_msg}), 500

@app.route('/ai/jobs/categories', methods=['GET'])
def get_job_categories():
    """ê³µê³  ì¹´í…Œê³ ë¦¬ ëª©ë¡ ì¡°íšŒ"""
    if not JOB_RECOMMENDATION_AVAILABLE:
        return jsonify({"error": "ê³µê³ ì¶”ì²œ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 500
    
    try:
        categories = {
            "BM": "ê²½ì˜/ê´€ë¦¬ì§",
            "SM": "ì˜ì—…/ë§ˆì¼€íŒ…",
            "PS": "ìƒì‚°/ê¸°ìˆ ì§",
            "RND": "ì—°êµ¬ê°œë°œ",
            "ICT": "IT/ì •ë³´í†µì‹ ",
            "ARD": "ë””ìì¸/ì˜ˆìˆ ",
            "MM": "ë¯¸ë””ì–´/ë°©ì†¡"
        }
        
        return jsonify({
            "status": "success",
            "categories": categories,
            "total_count": len(categories)
        })
    except Exception as e:
        return jsonify({"error": f"ì¹´í…Œê³ ë¦¬ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}"}), 500

@app.route('/ai/jobs/stats', methods=['GET'])  
def get_job_statistics():
    """ê³µê³  í†µê³„ ì •ë³´ ì¡°íšŒ"""
    if not JOB_RECOMMENDATION_AVAILABLE:
        return jsonify({"error": "ê³µê³ ì¶”ì²œ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 500
    
    try:
        result = job_recommendation_module.get_category_statistics()
        return jsonify(result)
    except Exception as e:
        error_msg = f"í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        logger.error(error_msg)
        return jsonify({"error": error_msg}), 500

# ==================== ê°œì¸ë©´ì ‘ API ì—”ë“œí¬ì¸íŠ¸ ====================

@app.route('/ai/interview/start', methods=['POST'])
def start_interview():
    """ê°œì¸ë©´ì ‘ ì‹œì‘ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        data = request.json or {}
        logger.info(f"ê°œì¸ë©´ì ‘ ì‹œì‘ ìš”ì²­: {data}")
        
        return jsonify({
            "status": "success",
            "interview_id": int(time.time()),
            "message": "ê°œì¸ë©´ì ‘ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "first_question": get_fixed_interview_question("general"),
            "server_type": "test_server"
        })
    except Exception as e:
        return jsonify({"error": f"ê°œì¸ë©´ì ‘ ì‹œì‘ ì¤‘ ì˜¤ë¥˜: {str(e)}"}), 500

@app.route('/ai/interview/<int:interview_id>/question', methods=['GET'])
def get_interview_question(interview_id):
    """ë©´ì ‘ ì§ˆë¬¸ ìƒì„± (ê³ ì • ì§ˆë¬¸ ì‚¬ìš©)"""
    try:
        question_type = request.args.get('type', 'general')
        question = get_fixed_interview_question(question_type)
        
        return jsonify({
            "interview_id": interview_id,
            "question": question,
            "question_type": question_type,
            "generated_by": "fixed_template"
        })
    except Exception as e:
        return jsonify({"error": f"ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"}), 500

@app.route('/ai/interview/<int:interview_id>/answer-video', methods=['POST'])
def process_interview_answer(interview_id):
    """ê°œì¸ë©´ì ‘ ë‹µë³€ ì˜ìƒ ì²˜ë¦¬ (ì‹¤ì œ AI ëª¨ë“ˆ ì‚¬ìš©)"""
    try:
        if 'file' not in request.files and 'video' not in request.files:
            return jsonify({"error": "ì˜ìƒ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        file = request.files.get('file') or request.files.get('video')
        
        # ì„ì‹œ íŒŒì¼ ì €ì¥
        temp_path = f"temp_interview_{interview_id}_{int(time.time())}.mp4"
        file.save(temp_path)
        
        temp_files = [temp_path]
        
        try:
            # ì˜¤ë””ì˜¤ ì¶”ì¶œ
            audio_path = extract_audio_from_video(temp_path)
            if audio_path:
                temp_files.append(audio_path)
            
            # Whisper ìŒì„± ì¸ì‹
            transcription_result = transcribe_with_whisper(audio_path) if audio_path else get_default_transcription()
            
            # Librosa ì˜¤ë””ì˜¤ ë¶„ì„
            audio_analysis = process_audio_with_librosa(audio_path) if audio_path else get_default_audio_analysis()
            
            # OpenFace ì–¼êµ´ ë¶„ì„
            facial_analysis = analyze_with_openface(temp_path)
            
            # ì¢…í•© ì ìˆ˜ ê³„ì‚°
            content_score = calculate_content_score(transcription_result.get("text", ""))
            voice_score = min(5.0, audio_analysis.get("voice_stability", 0.8) * 5)
            action_score = min(5.0, facial_analysis.get("confidence", 0.8) * 5)
            
            # ê²°ê³¼ êµ¬ì„±
            result = {
                "interview_id": interview_id,
                "transcription": transcription_result.get("text", ""),
                "transcription_confidence": transcription_result.get("confidence", 0.85),
                "analysis": {
                    "content_score": content_score,
                    "voice_score": voice_score,
                    "action_score": action_score,
                    "fluency": audio_analysis.get("fluency_score", 0.85),
                    "emotion": facial_analysis.get("emotion", "ì¤‘ë¦½"),
                    "voice_stability": audio_analysis.get("voice_stability", 0.8),
                    "speaking_rate": audio_analysis.get("speaking_rate_wpm", 120)
                },
                "feedback": generate_comprehensive_feedback(transcription_result, audio_analysis, facial_analysis),
                "next_question": "ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ë„˜ì–´ê°€ì‹œê² ìŠµë‹ˆê¹Œ?",
                "processing_methods": {
                    "transcription": "whisper" if WHISPER_AVAILABLE else "default",
                    "audio_analysis": "librosa" if LIBROSA_AVAILABLE else "default",
                    "facial_analysis": "openface" if OPENFACE_AVAILABLE else "default"
                },
                "server_type": "test_server"
            }
            
            # TTS ë³€í™˜ (ì„ íƒì )
            if TTS_AVAILABLE and transcription_result.get("text"):
                tts_path = f"temp_tts_{interview_id}_{int(time.time())}.wav"
                synthesized_path = synthesize_with_tts(transcription_result["text"][:100], tts_path)
                if synthesized_path:
                    result["tts_output"] = synthesized_path
                    temp_files.append(tts_path)
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            cleanup_temp_files(temp_files)
            
            return jsonify(result)
            
        except Exception as e:
            cleanup_temp_files(temp_files)
            raise e
        
    except Exception as e:
        return jsonify({"error": f"ë‹µë³€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"}), 500

def calculate_content_score(text: str) -> float:
    """ë‚´ìš© ì ìˆ˜ ê³„ì‚°"""
    if not text:
        return 2.0
    
    base_score = 3.0
    word_count = len(text.split())
    
    if word_count > 50:
        base_score += 1.0
    elif word_count > 30:
        base_score += 0.5
    
    concrete_words = ["ì˜ˆë¥¼ ë“¤ì–´", "êµ¬ì²´ì ìœ¼ë¡œ", "ì‹¤ì œë¡œ", "ê²½í—˜", "ì‚¬ë¡€"]
    if any(word in text for word in concrete_words):
        base_score += 0.5
    
    return min(5.0, base_score)

def generate_comprehensive_feedback(transcription: Dict, audio: Dict, facial: Dict) -> str:
    """ì¢…í•© í”¼ë“œë°± ìƒì„±"""
    try:
        text = transcription.get("text", "")
        voice_stability = audio.get("voice_stability", 0.8)
        fluency = audio.get("fluency_score", 0.85)
        emotion = facial.get("emotion", "ì¤‘ë¦½")
        
        feedback_parts = []
        
        # ë‚´ìš© í‰ê°€
        if len(text) > 100:
            feedback_parts.append("ì¶©ë¶„í•œ ë‚´ìš©ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì…¨ìŠµë‹ˆë‹¤.")
        elif len(text) > 50:
            feedback_parts.append("ì ì ˆí•œ ê¸¸ì´ì˜ ë‹µë³€ì´ì—ˆìŠµë‹ˆë‹¤.")
        else:
            feedback_parts.append("ì¢€ ë” êµ¬ì²´ì ì¸ ë‹µë³€ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ìŒì„± í‰ê°€
        if voice_stability > 0.8:
            feedback_parts.append("ì•ˆì •ì ì¸ ìŒì„±ìœ¼ë¡œ ë°œí‘œí•˜ì…¨ìŠµë‹ˆë‹¤.")
        elif voice_stability > 0.6:
            feedback_parts.append("ëŒ€ì²´ë¡œ ì•ˆì •ì ì¸ ìŒì„±ì´ì—ˆìŠµë‹ˆë‹¤.")
        else:
            feedback_parts.append("ìŒì„±ì˜ ì•ˆì •ì„±ì„ ë†’ì—¬ë³´ì„¸ìš”.")
        
        # ìœ ì°½ì„± í‰ê°€
        if fluency > 0.8:
            feedback_parts.append("ìœ ì°½í•˜ê²Œ ë°œí‘œí•˜ì…¨ìŠµë‹ˆë‹¤.")
        elif fluency > 0.6:
            feedback_parts.append("ì ì ˆí•œ ì†ë„ë¡œ ë°œí‘œí•˜ì…¨ìŠµë‹ˆë‹¤.")
        else:
            feedback_parts.append("ë°œí‘œ ì†ë„ì™€ ìœ ì°½ì„±ì„ ê°œì„ í•´ë³´ì„¸ìš”.")
        
        # ê°ì • ìƒíƒœ í‰ê°€
        if emotion in ["ê¸ì •ì ", "ìì‹ ê°"]:
            feedback_parts.append("ê¸ì •ì ì¸ í‘œì •ìœ¼ë¡œ ë©´ì ‘ì— ì„í•˜ì…¨ìŠµë‹ˆë‹¤.")
        elif emotion == "ì¤‘ë¦½":
            feedback_parts.append("ì•ˆì •ì ì¸ í‘œì •ì„ ìœ ì§€í•˜ì…¨ìŠµë‹ˆë‹¤.")
        
        return " ".join(feedback_parts)
        
    except Exception as e:
        logger.error(f"í”¼ë“œë°± ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return "ì „ë°˜ì ìœ¼ë¡œ ì–‘í˜¸í•œ ë‹µë³€ì´ì—ˆìŠµë‹ˆë‹¤. ê³„ì†í•´ì„œ ì—°ìŠµí•˜ì‹œë©´ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤."

# ==================== í† ë¡ ë©´ì ‘ API ì—”ë“œí¬ì¸íŠ¸ ====================

@app.route('/ai/debate/<int:debate_id>/ai-opening', methods=['POST'])
def ai_opening(debate_id):
    """AI ì…ë¡  ìƒì„± ì—”ë“œí¬ì¸íŠ¸ (ê³ ì • ì‘ë‹µ)"""
    try:
        data = request.json or {}
        logger.info(f"AI ì…ë¡  ìƒì„± ìš”ì²­: /ai/debate/{debate_id}/ai-opening")
        
        topic = data.get("topic", "ì¸ê³µì§€ëŠ¥")
        position = data.get("position", "CON")
        
        ai_response = get_fixed_ai_response("opening", topic)
        
        # TTS ë³€í™˜ (ì„ íƒì )
        tts_path = None
        if TTS_AVAILABLE and len(ai_response) > 0:
            tts_path = f"temp_tts_{debate_id}_{int(time.time())}.wav"
            synthesized_path = synthesize_with_tts(ai_response, tts_path)
            if not synthesized_path:
                tts_path = None
        
        response = {
            "ai_opening_text": ai_response,
            "generated_by": "fixed_template",
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "server_type": "test_server"
        }
        
        if tts_path:
            response["tts_output"] = tts_path
        
        return jsonify(response)
        
    except Exception as e:
        return jsonify({"error": f"AI ì…ë¡  ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"}), 500

@app.route('/ai/debate/<int:debate_id>/opening-video', methods=['POST'])
def process_opening_video(debate_id):
    """ì‚¬ìš©ì ì…ë¡  ì˜ìƒ ì²˜ë¦¬"""
    return process_debate_video_generic(debate_id, "opening", "rebuttal")

@app.route('/ai/debate/<int:debate_id>/rebuttal-video', methods=['POST'])
def process_rebuttal_video(debate_id):
    """ì‚¬ìš©ì ë°˜ë¡  ì˜ìƒ ì²˜ë¦¬"""
    return process_debate_video_generic(debate_id, "rebuttal", "counter_rebuttal")

@app.route('/ai/debate/<int:debate_id>/counter-rebuttal-video', methods=['POST'])
def process_counter_rebuttal_video(debate_id):
    """ì‚¬ìš©ì ì¬ë°˜ë¡  ì˜ìƒ ì²˜ë¦¬"""
    return process_debate_video_generic(debate_id, "counter_rebuttal", "closing")

@app.route('/ai/debate/<int:debate_id>/closing-video', methods=['POST'])
def process_closing_video(debate_id):
    """ì‚¬ìš©ì ìµœì¢… ë³€ë¡  ì˜ìƒ ì²˜ë¦¬"""
    return process_debate_video_generic(debate_id, "closing", None)

def process_debate_video_generic(debate_id, current_stage, next_ai_stage):
    """í† ë¡  ì˜ìƒ ì²˜ë¦¬ ê³µí†µ í•¨ìˆ˜ (ì‹¤ì œ AI ëª¨ë“ˆ ì‚¬ìš©)"""
    logger.info(f"{current_stage} ì˜ìƒ ì²˜ë¦¬ ìš”ì²­: /ai/debate/{debate_id}/{current_stage}-video")
    
    if 'file' not in request.files and 'video' not in request.files:
        return jsonify({"error": "ì˜ìƒ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400
    
    file = request.files.get('file') or request.files.get('video')
    
    try:
        temp_path = f"temp_{current_stage}_{debate_id}_{int(time.time())}.mp4"
        file.save(temp_path)
        
        temp_files = [temp_path]
        
        # ì˜¤ë””ì˜¤ ì¶”ì¶œ
        audio_path = extract_audio_from_video(temp_path)
        if audio_path:
            temp_files.append(audio_path)
        
        # Whisper ìŒì„± ì¸ì‹
        transcription_result = transcribe_with_whisper(audio_path) if audio_path else get_default_transcription()
        
        # Librosa ì˜¤ë””ì˜¤ ë¶„ì„
        audio_analysis = process_audio_with_librosa(audio_path) if audio_path else get_default_audio_analysis()
        
        # OpenFace ì–¼êµ´ ë¶„ì„
        facial_analysis = analyze_with_openface(temp_path)
        
        # ì¢…í•© ì ìˆ˜ ê³„ì‚°
        scores = calculate_debate_scores_detailed(transcription_result, audio_analysis, facial_analysis)
        
        # ê²°ê³¼ êµ¬ì„±
        result = {
            f"user_{current_stage}_text": transcription_result.get("text", ""),
            "emotion": facial_analysis.get("emotion", "ì¤‘ë¦½ (ì•ˆì •ì )"),
            **scores,
            "processing_methods": {
                "transcription": "whisper" if WHISPER_AVAILABLE else "default",
                "audio_analysis": "librosa" if LIBROSA_AVAILABLE else "default", 
                "facial_analysis": "openface" if OPENFACE_AVAILABLE else "default"
            },
            "server_type": "test_server"
        }
        
        # ë‹¤ìŒ AI ì‘ë‹µ ìƒì„± (ê³ ì • ì‘ë‹µ)
        if next_ai_stage:
            topic = request.form.get("topic", "ì¸ê³µì§€ëŠ¥")
            user_text = transcription_result.get("text", "")
            ai_response = get_fixed_ai_response(next_ai_stage, topic, user_text)
            result[f"ai_{next_ai_stage}_text"] = ai_response
            
            # TTS ë³€í™˜ (ì„ íƒì )
            if TTS_AVAILABLE and len(ai_response) > 0:
                tts_path = f"temp_tts_{debate_id}_{next_ai_stage}_{int(time.time())}.wav"
                synthesized_path = synthesize_with_tts(ai_response, tts_path)
                if synthesized_path:
                    result[f"ai_{next_ai_stage}_tts"] = tts_path
                    temp_files.append(tts_path)
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        cleanup_temp_files(temp_files)
        
        return jsonify(result)
        
    except Exception as e:
        cleanup_temp_files(temp_files)
        return jsonify({"error": f"ì˜ìƒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"}), 500

def calculate_debate_scores_detailed(transcription: Dict, audio: Dict, facial: Dict) -> Dict[str, Any]:
    """ìƒì„¸í•œ í† ë¡  ì ìˆ˜ ê³„ì‚°"""
    try:
        text = transcription.get("text", "")
        confidence = transcription.get("confidence", 0.85)
        voice_stability = audio.get("voice_stability", 0.8)
        fluency = audio.get("fluency_score", 0.85)
        speaking_rate = audio.get("speaking_rate_wpm", 120)
        facial_confidence = facial.get("confidence", 0.8)
        
        # ê¸°ë³¸ ì ìˆ˜ ê³„ì‚°
        scores = {
            "initiative_score": min(5.0, 3.0 + confidence * 2),
            "collaborative_score": min(5.0, 3.0 + min(1.0, len(text.split()) / 80)),
            "communication_score": min(5.0, 3.0 + fluency * 2),
            "logic_score": min(5.0, 3.0 + calculate_logic_score_detailed(text)),
            "problem_solving_score": min(5.0, 3.0 + calculate_problem_solving_score_detailed(text)),
            "voice_score": min(5.0, voice_stability * 5),
            "action_score": min(5.0, facial_confidence * 5)
        }
        
        # ë§í•˜ê¸° ì†ë„ ë³´ì •
        if 80 <= speaking_rate <= 160:  # ì ì ˆí•œ ì†ë„
            scores["communication_score"] = min(5.0, scores["communication_score"] + 0.3)
        
        # í”¼ë“œë°± ìƒì„±
        feedback_categories = {
            "initiative": "ì ê·¹ì„±",
            "collaborative": "í˜‘ë ¥ì„±",
            "communication": "ì˜ì‚¬ì†Œí†µ",
            "logic": "ë…¼ë¦¬ì„±",
            "problem_solving": "ë¬¸ì œí•´ê²°",
            "voice": "ìŒì„±í’ˆì§ˆ",
            "action": "í–‰ë™í‘œí˜„"
        }
        
        for category, korean_name in feedback_categories.items():
            score = scores[f"{category}_score"]
            if score >= 4.5:
                scores[f"{category}_feedback"] = f"{korean_name}: ë§¤ìš° ìš°ìˆ˜í•¨"
            elif score >= 4.0:
                scores[f"{category}_feedback"] = f"{korean_name}: ìš°ìˆ˜í•¨"
            elif score >= 3.5:
                scores[f"{category}_feedback"] = f"{korean_name}: ì–‘í˜¸í•¨"
            elif score >= 3.0:
                scores[f"{category}_feedback"] = f"{korean_name}: ë³´í†µ"
            else:
                scores[f"{category}_feedback"] = f"{korean_name}: ê°œì„  í•„ìš”"
        
        # ì¢…í•© í”¼ë“œë°±
        avg_score = sum(scores[k] for k in scores if k.endswith("_score")) / 7
        if avg_score >= 4.5:
            scores["feedback"] = "ë§¤ìš° ìš°ìˆ˜í•œ í† ë¡  ìˆ˜í–‰ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. ë…¼ë¦¬ì  êµ¬ì„±ê³¼ í‘œí˜„ë ¥ì´ ë›°ì–´ë‚©ë‹ˆë‹¤."
        elif avg_score >= 4.0:
            scores["feedback"] = "ìš°ìˆ˜í•œ í† ë¡  ìˆ˜í–‰ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ ì•ˆì •ì ì¸ ë°œí‘œì˜€ìŠµë‹ˆë‹¤."
        elif avg_score >= 3.5:
            scores["feedback"] = "ì–‘í˜¸í•œ í† ë¡  ìˆ˜í–‰ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. ëª‡ ê°€ì§€ ë¶€ë¶„ì—ì„œ ë” ë°œì „ì‹œí‚¬ ì—¬ì§€ê°€ ìˆìŠµë‹ˆë‹¤."
        elif avg_score >= 3.0:
            scores["feedback"] = "ê¸°ë³¸ì ì¸ í† ë¡  ìˆ˜í–‰ì€ ì–‘í˜¸í•©ë‹ˆë‹¤. ì¢€ ë” ì ê·¹ì ì¸ ìì„¸ì™€ ëª…í™•í•œ í‘œí˜„ì´ í•„ìš”í•©ë‹ˆë‹¤."
        else:
            scores["feedback"] = "í† ë¡  ìˆ˜í–‰ì— ì „ë°˜ì ì¸ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤. ì¶©ë¶„í•œ ì¤€ë¹„ì™€ ì—°ìŠµì„ í†µí•´ ë°œì „ì‹œì¼œ ë³´ì„¸ìš”."
        
        scores["sample_answer"] = generate_sample_answer(text, avg_score)
        
        return scores
        
    except Exception as e:
        logger.error(f"í† ë¡  ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
        return get_default_debate_scores()

def calculate_logic_score_detailed(text: str) -> float:
    """ìƒì„¸í•œ ë…¼ë¦¬ì„± ì ìˆ˜ ê³„ì‚°"""
    logic_indicators = ["ë”°ë¼ì„œ", "ê·¸ëŸ¬ë¯€ë¡œ", "ê²°ë¡ ì ìœ¼ë¡œ", "ì™œëƒí•˜ë©´", "ê·¼ê±°ëŠ”", "ì˜ˆë¥¼ ë“¤ì–´", "ì²«ì§¸", "ë‘˜ì§¸", "ì…‹ì§¸"]
    logic_count = sum(1 for indicator in logic_indicators if indicator in text)
    
    # í…ìŠ¤íŠ¸ ê¸¸ì´ ê³ ë ¤
    text_length_bonus = min(0.3, len(text) / 200)
    
    return min(2.0, logic_count * 0.3 + text_length_bonus)

def calculate_problem_solving_score_detailed(text: str) -> float:
    """ìƒì„¸í•œ ë¬¸ì œí•´ê²° ì ìˆ˜ ê³„ì‚°"""
    problem_solving_indicators = ["í•´ê²°", "ë°©ì•ˆ", "ëŒ€ì•ˆ", "ê°œì„ ", "ì „ëµ", "ì ‘ê·¼", "í•´ê²°ì±…", "ë°©ë²•"]
    problem_count = sum(1 for indicator in problem_solving_indicators if indicator in text)
    
    # êµ¬ì²´ì„± ë³´ë„ˆìŠ¤
    concrete_indicators = ["êµ¬ì²´ì ìœ¼ë¡œ", "ì‹¤ì œë¡œ", "ì‹¤ì²œ", "êµ¬í˜„", "ì ìš©"]
    concrete_count = sum(1 for indicator in concrete_indicators if indicator in text)
    
    return min(2.0, problem_count * 0.3 + concrete_count * 0.2)

def generate_sample_answer(user_text: str, avg_score: float) -> str:
    """ìƒ˜í”Œ ë‹µë³€ ìƒì„±"""
    if avg_score >= 4.0:
        return "ë…¼ë¦¬ì  êµ¬ì„±ê³¼ êµ¬ì²´ì  ì˜ˆì‹œê°€ ì˜ ì–´ìš°ëŸ¬ì§„ ë‹µë³€ì´ì—ˆìŠµë‹ˆë‹¤. ì´ëŸ° ìˆ˜ì¤€ì„ ìœ ì§€í•˜ì„¸ìš”."
    elif avg_score >= 3.5:
        return "ê¸°ë³¸ì ì¸ êµ¬ì„±ì€ ì¢‹ì•˜ìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ê·¼ê±°ì™€ ì˜ˆì‹œë¥¼ ì¶”ê°€í•˜ë©´ ë”ìš± ì„¤ë“ë ¥ìˆëŠ” ë‹µë³€ì´ ë  ê²ƒì…ë‹ˆë‹¤."
    else:
        return "ë…¼ë¦¬ì  êµ¬ì¡°ë¥¼ ê°–ì¶”ê³  êµ¬ì²´ì  ì˜ˆì‹œë¥¼ ë“¤ì–´ ì„¤ëª…í•˜ëŠ” ì—°ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤. 'ì²«ì§¸, ë‘˜ì§¸, ì…‹ì§¸' ê°™ì€ í‘œí˜„ì„ í™œìš©í•´ë³´ì„¸ìš”."

def get_default_debate_scores() -> Dict[str, Any]:
    """ê¸°ë³¸ í† ë¡  ì ìˆ˜"""
    return {
        "initiative_score": 3.5,
        "collaborative_score": 3.2,
        "communication_score": 3.8,
        "logic_score": 3.3,
        "problem_solving_score": 3.5,
        "voice_score": 3.7,
        "action_score": 3.9,
        "initiative_feedback": "ì ê·¹ì„±: ë³´í†µ",
        "collaborative_feedback": "í˜‘ë ¥ì„±: ë³´í†µ",
        "communication_feedback": "ì˜ì‚¬ì†Œí†µ: ì–‘í˜¸",
        "logic_feedback": "ë…¼ë¦¬ì„±: ë³´í†µ",
        "problem_solving_feedback": "ë¬¸ì œí•´ê²°: ë³´í†µ",
        "voice_feedback": "ìŒì„±í’ˆì§ˆ: ì–‘í˜¸",
        "action_feedback": "í–‰ë™í‘œí˜„: ì–‘í˜¸",
        "feedback": "ì „ë°˜ì ìœ¼ë¡œ ì–‘í˜¸í•œ ìˆ˜í–‰ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.",
        "sample_answer": "êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ ê·¼ê±°ë¥¼ ë“¤ì–´ ë…¼ë¦¬ì ìœ¼ë¡œ ì„¤ëª…í•´ë³´ì„¸ìš”."
    }

# AI ë‹¨ê³„ë³„ ì‘ë‹µ ì—”ë“œí¬ì¸íŠ¸ë“¤ (ê³ ì • ì‘ë‹µ)
@app.route('/ai/debate/<int:debate_id>/ai-rebuttal', methods=['GET'])
def ai_rebuttal(debate_id):
    """AI ë°˜ë¡  ìƒì„± (ê³ ì • ì‘ë‹µ)"""
    try:
        topic = request.args.get("topic", "ì¸ê³µì§€ëŠ¥")
        ai_response = get_fixed_ai_response("rebuttal", topic)
        return jsonify({"debate_id": debate_id, "ai_rebuttal_text": ai_response, "generated_by": "fixed_template"})
    except Exception as e:
        return jsonify({"error": f"AI ë°˜ë¡  ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"}), 500

@app.route('/ai/debate/<int:debate_id>/ai-counter-rebuttal', methods=['GET'])
def ai_counter_rebuttal(debate_id):
    """AI ì¬ë°˜ë¡  ìƒì„± (ê³ ì • ì‘ë‹µ)"""
    try:
        topic = request.args.get("topic", "ì¸ê³µì§€ëŠ¥")
        ai_response = get_fixed_ai_response("counter_rebuttal", topic)
        return jsonify({"debate_id": debate_id, "ai_counter_rebuttal_text": ai_response, "generated_by": "fixed_template"})
    except Exception as e:
        return jsonify({"error": f"AI ì¬ë°˜ë¡  ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"}), 500

@app.route('/ai/debate/<int:debate_id>/ai-closing', methods=['GET'])
def ai_closing(debate_id):
    """AI ìµœì¢… ë³€ë¡  ìƒì„± (ê³ ì • ì‘ë‹µ)"""
    try:
        topic = request.args.get("topic", "ì¸ê³µì§€ëŠ¥")
        ai_response = get_fixed_ai_response("closing", topic)
        return jsonify({"debate_id": debate_id, "ai_closing_text": ai_response, "generated_by": "fixed_template"})
    except Exception as e:
        return jsonify({"error": f"AI ìµœì¢… ë³€ë¡  ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"}), 500

@app.route('/ai/debate/modules-status', methods=['GET'])
def modules_status():
    """ëª¨ë“ˆ ìƒíƒœ í™•ì¸"""
    return jsonify({
        "status": "active",
        "server_type": "test_server",
        "note": "LLM ëª¨ë“ˆ ì œì™¸, ë‚˜ë¨¸ì§€ AI ëª¨ë“ˆ ì‚¬ìš© + ê³ ì • ì‘ë‹µ",
        "modules": {
            "llm": {
                "available": False,
                "note": "LLM ëŒ€ì‹  ê³ ì • ì‘ë‹µ ì‚¬ìš©"
            },
            "openface": {
                "available": OPENFACE_AVAILABLE,
                "functions": ["analyze_video", "extract_features"] if OPENFACE_AVAILABLE else []
            },
            "whisper": {
                "available": WHISPER_AVAILABLE,
                "functions": ["transcribe_video"] if WHISPER_AVAILABLE else []
            },
            "tts": {
                "available": TTS_AVAILABLE,
                "functions": ["text_to_speech"] if TTS_AVAILABLE else []
            },
            "librosa": {
                "available": LIBROSA_AVAILABLE,
                "functions": ["analyze_audio", "extract_features"] if LIBROSA_AVAILABLE else []
            },
            "job_recommendation": {
                "available": JOB_RECOMMENDATION_AVAILABLE,
                "functions": ["recommend_jobs", "get_categories"] if JOB_RECOMMENDATION_AVAILABLE else []
            }
        },
        "fixed_responses": {
            "opening": get_fixed_ai_response("opening"),
            "rebuttal": get_fixed_ai_response("rebuttal"),
            "counter_rebuttal": get_fixed_ai_response("counter_rebuttal"),
            "closing": get_fixed_ai_response("closing")
        }
    })

if __name__ == "__main__":
    # ì‹œì‘ ì‹œ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    initialize_test_systems()
    
    print("ğŸš€ VeriView AI í…ŒìŠ¤íŠ¸ ì„œë²„ ì‹œì‘...")
    print("ğŸ“ ì„œë²„ ì£¼ì†Œ: http://localhost:5000")
    print("ğŸ” í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸: http://localhost:5000/ai/test")
    print("ğŸ“Š ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸: http://localhost:5000/ai/debate/modules-status")
    print("ğŸ¯ í† ë¡ ë©´ì ‘ API: http://localhost:5000/ai/debate/<debate_id>/ai-opening")
    print("ğŸ’¼ ê°œì¸ë©´ì ‘ API: http://localhost:5000/ai/interview/start")
    print("ğŸ“‹ ê³µê³ ì¶”ì²œ API: http://localhost:5000/ai/jobs/recommend")
    print("=" * 80)
    print("í¬í•¨ëœ AI ëª¨ë“ˆ (LLM ì œì™¸):")
    print(f"  - OpenFace: {'âœ…' if OPENFACE_AVAILABLE else 'âŒ'}")
    print(f"  - Whisper: {'âœ…' if WHISPER_AVAILABLE else 'âŒ'}")
    print(f"  - TTS: {'âœ…' if TTS_AVAILABLE else 'âŒ'}")
    print(f"  - Librosa: {'âœ…' if LIBROSA_AVAILABLE else 'âŒ'}")
    print(f"  - ê³µê³ ì¶”ì²œ: {'âœ…' if JOB_RECOMMENDATION_AVAILABLE else 'âŒ'}")
    print("  - LLM: âŒ (ê³ ì • ì‘ë‹µ ì‚¬ìš©)")
    print("=" * 80)
    print("âš ï¸  ì£¼ì˜: ì´ ì„œë²„ëŠ” LLMì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ê³ ì •ëœ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.")
    print("ğŸ’¡ ì‹¤ì œ LLM ê¸°ëŠ¥ì„ ì›í•˜ì‹œë©´ main_server.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    print("=" * 80)
    
    app.run(host="0.0.0.0", port=5000, debug=True)
